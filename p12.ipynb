{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "022723d6-4f76-4b13-b9db-d5b17edc76d5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Project 12: Web Requests, Caching, DataFrames and Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc07cc6-76bc-4fef-8b4f-86d370d6e2dd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Your Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f9139-9739-495a-ac69-d4ac40f0c363",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "At the start of each assignment, you will need to provide us your name and the name of the partner you worked with for this assignment (if you had one). Double click on the cell below or click once and hit enter to edit it. Replace \"First Last\" with your first name and last name. Replace \"None\" with the first and last name of your partner if you had one for this assignment. We ask for this information so we don't accuse you of cheating when your code looks like your partner's.\n",
    "\n",
    "Please keep these lines commented so they don't cause an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2556d5-2bef-4fed-be20-0229f1d69262",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# MY NAME: Hyokyung Kim\n",
    "\n",
    "# My PARTNER'S NAME: None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87abc1-a402-4b78-9dd6-36c2921941b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b765817-e1b0-4d95-84ab-4f330ec91039",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Every project will begin with some import statements. It's crucial that you run the cell below, otherwise we will not be able to grade your code and provide feedback to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a74012-6262-49e3-82f8-3e66d1b14fbc",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# it is considered a good coding practice to place all import statements at the top of the notebook\n",
    "# please place all your import statements in this cell if you need to import any more modules for this lab\n",
    "\n",
    "# we have imported these modules for you\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import student_grader\n",
    "student_grader.initialize(os.getcwd(), \"p12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f7446-d334-4e74-be57-33f1cb68e32c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h2 style=\"color:red\">Warning (Note on Academic Misconduct):</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053980e-dd43-423f-8faa-9a960c513428",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**IMPORTANT**: **P12 and P13 are two parts of the same data analysis.** You **cannot** switch project partners between these two projects. That is if you partner up with someone for P12, you have to sustain that partnership until the end of P13. Now may be a good time to review [our course policies](https://cs220.cs.wisc.edu/f24/syllabus.html).\n",
    "\n",
    "Under any circumstances, **no more than two students are allowed to work together on a project** as mentioned in the course policies. If your code is flagged by our code similarity detection tools, **both partners will be responsible** for sharing/copying the code, even if the code is shared/copied by one of the partners with/from other non-partner student(s). Note that each case of plagiarism will be reported to the Dean of Students with a zero grade on the project. **If you think that someone cannot be your project partner then don’t make that student your lab partner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f045a9b-9007-4176-9eb0-86c176122531",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Lab Portion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee8666-5f77-4c1c-8b78-757ae523df78",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94bdb90-5247-4064-a81c-bc0d432ed4c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In this lab, you will practice how to:\n",
    "\n",
    "* use HTTP requests to download content from the internet,\n",
    "* cache data onto your computer,\n",
    "* construct and modify DataFrames to analyze datasets,\n",
    "* use `BeautifulSoup` to parse web pages and extract useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc1717-4212-4e2d-aee8-82783dfe7c20",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Section 1: File handling with the `os` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a6dee0-e2a5-4394-b4a2-616457be33f3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 1: Fetch `rankings.json` from an internet URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d19507-cbbb-49a8-9ce0-14c5f889d58a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use the `requests` library to fetch the file at this URL:\n",
    "\n",
    "`https://cs220.cs.wisc.edu/projects/data/rankings.json`.\n",
    "\n",
    "Make sure to call the appropriate function to **raise** an HTTPError if status code is not `200`. Then create a variable called `file_text` that saves the text of the response.\n",
    "\n",
    "**Hint:** You can review the relevant lecture code here: [Mike](https://canvas.wisc.edu/courses/427075/files/folder/Mikes_Lecture_Notes/lec29_web_1), [Louis](https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-lecture-material/-/tree/main/f24/Louis_Lecture_Notes/29_Web1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6d6ab-86b0-4232-aec6-117932aef967",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b5f7f0-4917-4f3a-b9f0-f1521af6d686",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q1-code"
    ]
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://cs220.cs.wisc.edu/projects/data/rankings.json\"\n",
    "response = requests.get(url)\n",
    "\n",
    "response.raise_for_status()\n",
    "\n",
    "file_text = response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66095be1-2f1c-48f7-a194-5a3a645dbbf3",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q1...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q1\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2c475-b7c1-4057-8938-03750550f369",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 2: Save `rankings.json` as a file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc0c53-ab88-4351-8875-31ad95422b26",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Open a file in write mode called `rankings.json`, and write the contents of the variable `file_text` into it. Make sure to **close** the file afterwards (unless you used a `with` block to open the file).\n",
    "\n",
    "**Hint:** You can review the relevant lecture code here: [Mike](https://canvas.wisc.edu/courses/427075/files/folder/Mikes_Lecture_Notes/lec26_files_directories), [Louis](https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-lecture-material/-/tree/main/f24/Louis_Lecture_Notes/26_Files_and_Directories)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56c20c-a31f-484f-a2c0-e9e8dac8530c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d632701d-32bf-4413-abad-6fa4c4e96610",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q2-code"
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"rankings.json\", \"w\") as file:\n",
    "    file.write(file_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc8dac1-7c96-4123-ae77-e4a48e1cb385",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q2...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q2\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324e67f-3fe2-4f13-8306-911487cb6410",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Note that the cell above only checked if the file had been created, and **not** whether it contains the correct data. You must check that yourself. Check your `lab-p12` directory in Finder (Mac) / Explorer (Windows). It should now have a file called `rankings.json`. **Manually open** this file and confirm that it contains the contents of the page [rankings.json](https://cs220.cs.wisc.edu/projects/data/rankings.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0a610-9941-47ff-be12-995683e6f31b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Function 1: `download`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8efa77-6c76-471b-b1cf-212cb3457040",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, you will implement a function `download` to download data from the internet and save it to a file. \n",
    "\n",
    "This function takes in two arguments `url` and `filename`. The contents at the address pointed to by the `url` field should be saved into the file whose path is specified by `filename`. Remember that you can reuse the code you wrote above.\n",
    "\n",
    "The naive version of function `download` described above has one big disadvantage: it **downloads** the file even if it has already been created. Fetching data from webpages takes both time and resources, and **must** be avoided as much as possible. In particular, repeatedly downloading files that have been already downloaded is a **very bad** coding practices, and **must** be avoided.\n",
    "\n",
    "Therefore, we need to ensure the `download` function implements *caching*. This means that **before** downloading the file from the internet, the function **must** check if the file already exists. If the file already exists, the function should return the message `\"<filename> already exists!\"` where `filename` is the argument. It should **not** make a request. Don't forget the space between `<filename>` and the following word.\n",
    "\n",
    "**Hint:** You can use the `os.path.exists` function to check if the `filename` already exists.\n",
    "\n",
    "**Hint:** If you're struggling to pass the test, we've shown you the code that we are using to test your `download` function in lab question 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c5b2e-fcea-4de1-bc5f-97a9f19ed2b0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e5fb9df-36af-4902-b652-99e98e42baf4",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-function-download-code"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download(url, filename):\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(filename):\n",
    "        return f\"{filename} already exists!\"\n",
    "    \n",
    "    # Make the HTTP request\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "    \n",
    "    # Get the text content\n",
    "    file_text = response.text\n",
    "    \n",
    "    # Open the file with 'utf-8' encoding and write the text content\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(file_text)\n",
    "    \n",
    "    return f\"{filename} created!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c565eb00-3212-4385-ad8c-09e284291377",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-function-download...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-function-download\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c967a-2c00-4272-b33c-1e0f417ba34f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 3: Test the `download` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d177166-7fc9-4e64-9303-af404b41af06",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Below is the code we used to check if your `download` function is correct.\n",
    "\n",
    "The cell checks whether the `download` function checks existing files, and whether it correctly downloads files from the given address. An `assert` statement checks if a boolean expression is true and throws an error if not.\n",
    "\n",
    "**Do NOT modify the code in the cell below**. Think about why the test code is written in this way. Ask a TA if you're not sure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83bcd5-eb1f-4ea7-82a5-51c0e2a015ca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3794e5ac-bd81-4155-b5c1-8e24c83c8086",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q3-code"
    ]
   },
   "outputs": [],
   "source": [
    "# delete the file if it already exists and download the file\n",
    "rankings_url = \"https://cs220.cs.wisc.edu/projects/data/rankings.json\"\n",
    "\n",
    "if os.path.exists(\"rankings.json\"):\n",
    "    os.remove(\"rankings.json\") # delete the existing file\n",
    "\n",
    "return_result_1 = download(rankings_url, \"rankings.json\") # should be \"rankings.json created!\"\n",
    "file_size_1 = os.path.getsize(\"rankings.json\") # should be none-zero\n",
    "\n",
    "f = open(\"rankings.json\", \"w\") # rewrite the contents of the file\n",
    "f.close()\n",
    "\n",
    "return_result_2 = download(rankings_url, \"rankings.json\") # should be \"rankings.json already exists!\"\n",
    "file_size_2 = os.path.getsize(\"rankings.json\") # should be 0\n",
    "os.remove(\"rankings.json\")\n",
    "return_result_3 = download(rankings_url, \"rankings.json\") # should be \"rankings.json created!\"\n",
    "\n",
    "assert return_result_1 == \"rankings.json created!\"\n",
    "assert return_result_2 == \"rankings.json already exists!\"\n",
    "assert return_result_3 == \"rankings.json created!\"\n",
    "assert file_size_1 > 0\n",
    "assert file_size_2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "489672db-2b5f-47e5-9d4a-23e8da043209",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q3...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q3\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da21599a-f084-4131-875c-3e1ae9a1a7c4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You **must** use this `download` function to download files during P12. This will ensure that you do not download the files each time you 'Restart & Run All'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320bb98a-d803-402a-9915-4bc589aa9b11",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Section 2: Creating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5ceaf-95ae-4d12-9ea3-8f7e26a2a56f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For this project, we will be analyzing statistics about world university rankings adapted from\n",
    "[here](https://cwur.org/). The `rankings.json` file was created by scraping content from pages on the linked website. \n",
    "\n",
    "We are going to use `pandas` throughout the lab and project to analyze this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f4610-a55a-4975-a1df-9fa9f2e0c013",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In lecture, you reviewed different ways to create pandas DataFrames. In this section, you will create a DataFrame `rankings` **by reading the JSON data** saved in `rankings.json`.\n",
    "\n",
    "The output of the next cell must look like this:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Year</th>\n",
    "      <th>World Rank</th>\n",
    "      <th>Institution</th>\n",
    "      <th>Country</th>\n",
    "      <th>National Rank</th>\n",
    "      <th>Education Rank</th>\n",
    "      <th>Employability Rank</th>\n",
    "      <th>Faculty Rank</th>\n",
    "      <th>Research Rank</th>\n",
    "      <th>Score</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>2021</td>\n",
    "      <td>1</td>\n",
    "      <td>Harvard University</td>\n",
    "      <td>USA</td>\n",
    "      <td>1</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>100.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>2021</td>\n",
    "      <td>2</td>\n",
    "      <td>Massachusetts Institute of Technology</td>\n",
    "      <td>USA</td>\n",
    "      <td>2</td>\n",
    "      <td>4.0</td>\n",
    "      <td>12.0</td>\n",
    "      <td>2.0</td>\n",
    "      <td>8.0</td>\n",
    "      <td>96.7</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>2021</td>\n",
    "      <td>3</td>\n",
    "      <td>Stanford University</td>\n",
    "      <td>USA</td>\n",
    "      <td>3</td>\n",
    "      <td>10.0</td>\n",
    "      <td>4.0</td>\n",
    "      <td>3.0</td>\n",
    "      <td>2.0</td>\n",
    "      <td>95.1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>2021</td>\n",
    "      <td>4</td>\n",
    "      <td>University of Cambridge</td>\n",
    "      <td>United Kingdom</td>\n",
    "      <td>1</td>\n",
    "      <td>3.0</td>\n",
    "      <td>25.0</td>\n",
    "      <td>4.0</td>\n",
    "      <td>10.0</td>\n",
    "      <td>94.1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>2021</td>\n",
    "      <td>5</td>\n",
    "      <td>University of Oxford</td>\n",
    "      <td>United Kingdom</td>\n",
    "      <td>2</td>\n",
    "      <td>7.0</td>\n",
    "      <td>27.0</td>\n",
    "      <td>9.0</td>\n",
    "      <td>4.0</td>\n",
    "      <td>93.3</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37e568c2-7bad-449a-8b82-a6962b3c9111",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>World Rank</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Country</th>\n",
       "      <th>National Rank</th>\n",
       "      <th>Education Rank</th>\n",
       "      <th>Employability Rank</th>\n",
       "      <th>Faculty Rank</th>\n",
       "      <th>Research Rank</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>96.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>94.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  World Rank                            Institution         Country  \\\n",
       "0  2021           1                     Harvard University             USA   \n",
       "1  2021           2  Massachusetts Institute of Technology             USA   \n",
       "2  2021           3                    Stanford University             USA   \n",
       "3  2021           4                University of Cambridge  United Kingdom   \n",
       "4  2021           5                   University of Oxford  United Kingdom   \n",
       "\n",
       "   National Rank  Education Rank  Employability Rank  Faculty Rank  \\\n",
       "0              1             1.0                 1.0           1.0   \n",
       "1              2             4.0                12.0           2.0   \n",
       "2              3            10.0                 4.0           3.0   \n",
       "3              1             3.0                25.0           4.0   \n",
       "4              2             7.0                27.0           9.0   \n",
       "\n",
       "   Research Rank  Score  \n",
       "0            1.0  100.0  \n",
       "1            8.0   96.7  \n",
       "2            2.0   95.1  \n",
       "3           10.0   94.1  \n",
       "4            4.0   93.3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have done this one for you\n",
    "\n",
    "rankings = pd.read_json('rankings.json')\n",
    "rankings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a4f37-dd45-4130-b014-9d774850fd1d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 4: Find the unique universities in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201aa558-126a-4297-a085-6e4e4f16290c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As the dataset contains rankings for three different years, the same university may have featured multiple times. Find the names of the unique universities that are represented in the dataset.\n",
    "\n",
    "First, extract just the names of the institutions as a `pandas` **Series**. Then, make a **list** of unique names called `institutions_list`. **Series** can be easily typecast just like any other data type in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfde772-77b9-4b45-818e-079a670cd04d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b09d478-734d-44c3-b623-c57fdc4317de",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q4-code"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rankings = pd.read_json(\"rankings.json\")  \n",
    "\n",
    "institutions = rankings[\"Institution\"]\n",
    "\n",
    "institutions_list = list(set(institutions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "236d2b8c-a440-47ee-9864-39730571b0e7",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q4...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q4\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9414b8f5-6977-4960-a254-daec70228383",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Section 3: Use `value_counts` to count instances in a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626019df-6583-41c6-9bef-bd1ce7958d8e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, let's find the country that is the 5th most represented in the dataframe, and the number of times it features. Recall that `value_counts` enables us to count number of occurrences of unique values in a pandas **Series**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c079046-6b2e-4cf4-b51e-a4bc2c34c7ef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 5: Obtain the counts for all countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b726b42-7c09-4d66-a691-fc25a93cb68e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "First, use the `value_counts` function on the `Country` column of `rankings`, and then typecast to a pandas **Series** called `country_counts`. This **Series** should contain each country in the dataset and the number of times it occurs.\n",
    "\n",
    "**Hint:** You can review the relevant lecture code here: [Mike](https://canvas.wisc.edu/courses/427075/files/folder/Mikes_Lecture_Notes/lec27_pandas_1), [Louis](https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-lecture-material/-/tree/main/f24/Louis_Lecture_Notes/27_Pandas1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2ccc6-ece8-4c41-a6ec-292cea24653c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fb3c82b-fb60-4352-a733-2f0436fd2700",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q5-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5th most represented country is France with 232 occurrences.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rankings = pd.read_json(\"rankings.json\") \n",
    "\n",
    "country_counts = rankings[\"Country\"].value_counts()\n",
    "\n",
    "country_counts = pd.Series(country_counts)\n",
    "\n",
    "fifth_country = country_counts.index[4]\n",
    "fifth_count = country_counts.iloc[4]\n",
    "\n",
    "print(f\"The 5th most represented country is {fifth_country} with {fifth_count} occurrences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7875b91-ab08-45c2-8c76-0f26f86601cd",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q5...\n",
      "The 5th most represented country is France with 232 occurrences.\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q5\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd76ce0-d1e4-4e55-9b75-d5f34efb66fc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 6: Find the 5th most represented country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35613ff-b272-49f4-b84f-8829a94e625c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use the `.index` attribute of the **Series** `country_counts` to fetch the name of the 5th most represented country. Note that `country_counts` is **sorted** in *decreasing* order of the number of times each country appears in `rankings`. You **must** use `loc` to fetch the count of this country. Make sure to use the **Series** `country_counts` defined in Question 5.\n",
    "\n",
    "**Hint**: The pandas `Series.index` works differently from the `.index` method you are familiar with for **lists**. `Series.index` takes in the numerical **index** of the element you want to access, and returns the **label** of the element. Then, you can pass the **label** to `.loc` to access the corresponding value in the `Series`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645063b4-924a-4d2f-ae3b-42a33618b8cc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67ed28b0-4bd3-4670-a7a5-4e622292c2a5",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q6-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France 232\n"
     ]
    }
   ],
   "source": [
    "# Find the name of the 5th most represented country\n",
    "fifth_country = country_counts.index[4]\n",
    "\n",
    "# Use .loc to fetch the count of this country\n",
    "fifth_count = country_counts.loc[fifth_country]\n",
    "\n",
    "# Print the results\n",
    "print(fifth_country, fifth_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b3459d7-67de-4d70-a5a0-be80fa7823f4",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q6...\n",
      "France 232\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q6\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6451b5d8-9182-4640-b9f9-4d19978f7803",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Section 4: `loc` vs `iloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa506c6-a162-46bf-b2e5-06a9f53136c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In this lab and project, you **must** only use `iloc` to access from a **DataFrame**. Using `loc` and explicitly hardcoding the `loc` of the row you want to access will be considered **hardcording**. This is because `iloc` selects rows and columns at the given **integer position** while `loc` selects rows at the given **pandas index**. \n",
    "\n",
    "Recall that **row index** can be given meaningful names like string indices. Consider a scenario where you add rows to the beginning of the DataFrame - if you use `.loc` indexing, your answer will become **incorrect** if the data changes. Whereas if you use `.iloc`, you will always get the correct answer.\n",
    "\n",
    "This distinction may not be as intuitive for the current `rankings` **DataFrame**. As an example, use both `loc` and `iloc` to fetch the first row in `rankings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28c35941-bc15-4a75-a5ba-63bf52b2457d",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                                2021\n",
       "World Rank                             1\n",
       "Institution           Harvard University\n",
       "Country                              USA\n",
       "National Rank                          1\n",
       "Education Rank                       1.0\n",
       "Employability Rank                   1.0\n",
       "Faculty Rank                         1.0\n",
       "Research Rank                        1.0\n",
       "Score                              100.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 'iloc' to extract the first row from 'rankings'\n",
    "\n",
    "first_row_iloc = rankings.iloc[0]\n",
    "first_row_iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5080aa88-04c9-4f2c-a566-8e8bd6f310a4",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                                2021\n",
       "World Rank                             1\n",
       "Institution           Harvard University\n",
       "Country                              USA\n",
       "National Rank                          1\n",
       "Education Rank                       1.0\n",
       "Employability Rank                   1.0\n",
       "Faculty Rank                         1.0\n",
       "Research Rank                        1.0\n",
       "Score                              100.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 'loc' to extract the first row from 'rankings'\n",
    "\n",
    "first_row_loc = rankings.loc[0]\n",
    "first_row_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b28fe8-98fe-4dcc-82cd-55f69c4aafac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The results are exactly the same! This happens since the integer positions correspond to the pandas indices in the `rankings` dataframe. **However, this will not always hold true** - as we see in the next question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a871372-47f6-4431-91a1-03ca268ac544",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 7: Use boolean indexing to filter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73093631-ab32-4925-aaa2-369526928ae2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, use **boolean indexing** to extract data from the **DataFrame**. You can find the relevant lecture code here: [Mike](https://canvas.wisc.edu/courses/427075/files/folder/Mikes_Lecture_Notes/lec28_pandas_2), [Louis](https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-lecture-material/-/tree/main/f24/Louis_Lecture_Notes/28_Pandas2).\n",
    "\n",
    "Create a **DataFrame** `rankings_arg_bra` that **only** consists of rankings of universities from *Argentina* or *Brazil*. \n",
    "\n",
    "**Hint**: When implementing **boolean indexing** in `pandas`, the `or` operator is represented by `|` and the `and` operator is represented by `&`. Remember that you should separate conditions with parentheses when performing boolean indexing with multiple conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f55c6-3cef-47d5-a636-695863c15ec6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40704eda-ac6f-4977-94c5-5a52ef51e0db",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q7-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  World Rank                           Institution    Country  \\\n",
      "104  2021         105               University of São Paulo     Brazil   \n",
      "346  2021         347                University of Campinas     Brazil   \n",
      "355  2021         356            University of Buenos Aires  Argentina   \n",
      "359  2021         360  Federal University of Rio de Janeiro     Brazil   \n",
      "420  2021         421            São Paulo State University     Brazil   \n",
      "\n",
      "     National Rank  Education Rank  Employability Rank  Faculty Rank  \\\n",
      "104              1           518.0               333.0         131.0   \n",
      "346              2             NaN                 NaN           NaN   \n",
      "355              1           319.0              1347.0           NaN   \n",
      "359              3           445.0               440.0           NaN   \n",
      "420              4             NaN                 NaN           NaN   \n",
      "\n",
      "     Research Rank  Score  \n",
      "104           85.0   81.5  \n",
      "346          310.0   76.0  \n",
      "355          324.0   75.9  \n",
      "359          336.0   75.8  \n",
      "420          394.0   75.0  \n"
     ]
    }
   ],
   "source": [
    "# Use boolean indexing to filter rows where the 'Country' column is 'Argentina' or 'Brazil'\n",
    "rankings_arg_bra = rankings[(rankings[\"Country\"] == \"Argentina\") | (rankings[\"Country\"] == \"Brazil\")]\n",
    "\n",
    "# Display the head of the resulting DataFrame\n",
    "print(rankings_arg_bra.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8067a1c-dc92-4c2f-bb79-67ed4996265f",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q7...\n",
      "     Year  World Rank                           Institution    Country  \\\n",
      "104  2021         105               University of São Paulo     Brazil   \n",
      "346  2021         347                University of Campinas     Brazil   \n",
      "355  2021         356            University of Buenos Aires  Argentina   \n",
      "359  2021         360  Federal University of Rio de Janeiro     Brazil   \n",
      "420  2021         421            São Paulo State University     Brazil   \n",
      "\n",
      "     National Rank  Education Rank  Employability Rank  Faculty Rank  \\\n",
      "104              1           518.0               333.0         131.0   \n",
      "346              2             NaN                 NaN           NaN   \n",
      "355              1           319.0              1347.0           NaN   \n",
      "359              3           445.0               440.0           NaN   \n",
      "420              4             NaN                 NaN           NaN   \n",
      "\n",
      "     Research Rank  Score  \n",
      "104           85.0   81.5  \n",
      "346          310.0   76.0  \n",
      "355          324.0   75.9  \n",
      "359          336.0   75.8  \n",
      "420          394.0   75.0  \n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q7\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d9a60-7e56-43ee-b6c2-c3eccd78ccb1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, we will try to extract the **first** value in this new **DataFrame** using `iloc` and `loc`. As you'll see, using `loc` will not work the same way it did before. In fact, it will throw an **error**. To verify, run the two cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49bf7a7b-106c-4af7-bb9a-6f09f19ed63b",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                                     2021\n",
       "World Rank                                105\n",
       "Institution           University of São Paulo\n",
       "Country                                Brazil\n",
       "National Rank                               1\n",
       "Education Rank                          518.0\n",
       "Employability Rank                      333.0\n",
       "Faculty Rank                            131.0\n",
       "Research Rank                            85.0\n",
       "Score                                    81.5\n",
       "Name: 104, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row_iloc = rankings_arg_bra.iloc[0]\n",
    "\n",
    "first_row_iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6b33af1-d2e5-416a-9f34-b69d32ec4057",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# uncomment this to see how .loc causes a KeyError\n",
    "# first_row_loc = rankings_arg_bra.loc[0]\n",
    "\n",
    "# first_row_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c4071-3d96-4c69-8f9f-055b65c99a09",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We see that using `.loc` now causes a **KeyError**.\n",
    "\n",
    "`.loc[0]` tries to find the row with the *labeled* **index** 0. Actually, `rankings_arg_bra` starts at the labeled **index** 104. There is no 0. Hence the **KeyError**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cd94dd-a64e-4bb2-a7c5-3b6dea2a401a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 8: Sort the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b184b0de-ac9d-462f-9ee5-9f81324b8d45",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The **DataFrame** in Question 7 is sorted by `World Rank`, with the result that universities from *Argentina* and *Brazil* are interleaved throughout the data. **Re-sort** the data to sort by `Country` so that all universities from *Argentina* appear **first** followed by universities from *Brazil*. Within each country, the universities should be **sorted** by their `National Rank`. \n",
    "\n",
    "Use the `sort_values` function of `pandas`. You can find the relevant lecture code here: [Mike](https://canvas.wisc.edu/courses/427075/files/folder/Mikes_Lecture_Notes/lec27_pandas_1), [Louis](https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-lecture-material/-/tree/main/f24/Louis_Lecture_Notes/31_Web3). Remember - by default, `pandas` returns a **new** sorted **DataFrame** and does **not** modify the existing one.\n",
    "\n",
    "Recall that `sort_values` takes an argument for the parameter `by` as the column name, based on which you want to do the sorting. If you want to use one column for primary sorting and another for secondary sorting, you can specify a **list** of column names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e20d5-0f4d-42e6-a5bf-170b9e0153e2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5103dba-45a2-4394-830e-54c43d7a99c7",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q8-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  World Rank                      Institution    Country  \\\n",
      "355   2021         356       University of Buenos Aires  Argentina   \n",
      "2364  2022         365       University of Buenos Aires  Argentina   \n",
      "4381  2023         382       University of Buenos Aires  Argentina   \n",
      "620   2021         621  National University of La Plata  Argentina   \n",
      "2638  2022         639  National University of La Plata  Argentina   \n",
      "...    ...         ...                              ...        ...   \n",
      "5938  2023        1939   Federal University of Amazonas     Brazil   \n",
      "1944  2021        1945   Federal University of Amazonas     Brazil   \n",
      "3962  2022        1963   Federal University of Amazonas     Brazil   \n",
      "1995  2021        1996  Santa Catarina State University     Brazil   \n",
      "3996  2022        1997   Federal University of Maranhão     Brazil   \n",
      "\n",
      "      National Rank  Education Rank  Employability Rank  Faculty Rank  \\\n",
      "355               1           319.0              1347.0           NaN   \n",
      "2364              1           319.0              1397.0           NaN   \n",
      "4381              1           321.0              1450.0           NaN   \n",
      "620               2             NaN              1451.0           NaN   \n",
      "2638              2             NaN              1516.0           NaN   \n",
      "...             ...             ...                 ...           ...   \n",
      "5938             54             NaN                 NaN           NaN   \n",
      "1944             55             NaN                 NaN           NaN   \n",
      "3962             55             NaN                 NaN           NaN   \n",
      "1995             56             NaN               936.0           NaN   \n",
      "3996             56             NaN                 NaN           NaN   \n",
      "\n",
      "      Research Rank  Score  \n",
      "355           324.0   75.9  \n",
      "2364          330.0   75.8  \n",
      "4381          352.0   75.7  \n",
      "620           589.0   73.0  \n",
      "2638          610.0   72.8  \n",
      "...             ...    ...  \n",
      "5938         1860.0   66.2  \n",
      "1944         1870.0   65.9  \n",
      "3962         1884.0   65.9  \n",
      "1995         1938.0   65.8  \n",
      "3996         1923.0   65.7  \n",
      "\n",
      "[193 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "rankings = pd.read_json(\"rankings.json\")  # Ensure the JSON file is loaded into a DataFrame\n",
    "\n",
    "# Filter the DataFrame for universities from Argentina or Brazil\n",
    "rankings_arg_bra = rankings[(rankings[\"Country\"] == \"Argentina\") | (rankings[\"Country\"] == \"Brazil\")]\n",
    "\n",
    "# Sort the filtered DataFrame by 'Country' and then by 'National Rank'\n",
    "sorted_rankings_arg_bra = rankings_arg_bra.sort_values(by=[\"Country\", \"National Rank\"])\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(sorted_rankings_arg_bra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60d6ccd6-c456-47ae-9cb7-785cc0cfb908",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q8...\n",
      "      Year  World Rank                      Institution    Country  \\\n",
      "355   2021         356       University of Buenos Aires  Argentina   \n",
      "2364  2022         365       University of Buenos Aires  Argentina   \n",
      "4381  2023         382       University of Buenos Aires  Argentina   \n",
      "620   2021         621  National University of La Plata  Argentina   \n",
      "2638  2022         639  National University of La Plata  Argentina   \n",
      "...    ...         ...                              ...        ...   \n",
      "5938  2023        1939   Federal University of Amazonas     Brazil   \n",
      "1944  2021        1945   Federal University of Amazonas     Brazil   \n",
      "3962  2022        1963   Federal University of Amazonas     Brazil   \n",
      "1995  2021        1996  Santa Catarina State University     Brazil   \n",
      "3996  2022        1997   Federal University of Maranhão     Brazil   \n",
      "\n",
      "      National Rank  Education Rank  Employability Rank  Faculty Rank  \\\n",
      "355               1           319.0              1347.0           NaN   \n",
      "2364              1           319.0              1397.0           NaN   \n",
      "4381              1           321.0              1450.0           NaN   \n",
      "620               2             NaN              1451.0           NaN   \n",
      "2638              2             NaN              1516.0           NaN   \n",
      "...             ...             ...                 ...           ...   \n",
      "5938             54             NaN                 NaN           NaN   \n",
      "1944             55             NaN                 NaN           NaN   \n",
      "3962             55             NaN                 NaN           NaN   \n",
      "1995             56             NaN               936.0           NaN   \n",
      "3996             56             NaN                 NaN           NaN   \n",
      "\n",
      "      Research Rank  Score  \n",
      "355           324.0   75.9  \n",
      "2364          330.0   75.8  \n",
      "4381          352.0   75.7  \n",
      "620           589.0   73.0  \n",
      "2638          610.0   72.8  \n",
      "...             ...    ...  \n",
      "5938         1860.0   66.2  \n",
      "1944         1870.0   65.9  \n",
      "3962         1884.0   65.9  \n",
      "1995         1938.0   65.8  \n",
      "3996         1923.0   65.7  \n",
      "\n",
      "[193 rows x 10 columns]\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q8\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae2ae2-9ab5-4bba-a229-2298b79f5e97",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Section 5: Create a new, simplified DataFrame to track changes in rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be30c0-84c8-46ee-93d6-8edd1b0b6e12",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As we have seen, universities that have featured in rankings of multiple years are featured repeatedly. To simplify comparisons, we want to feature each university once and remove all other metrics. \n",
    "\n",
    "This time - instead of simply ranking universities, we want to find the **absolute change** in universities' rankings between the years *2021* and *2022*. We are only interested in the absolute change and **not** whether the rank improved or declined.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9221173-75e3-4140-a7c6-45fd5894259f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 9: Find the absolute difference in `World Rank` for *\"University of Madras\"* between the `Year` *2021* and *2022*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa193cb-6532-4178-97bb-e6cf3b752afd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "First, let's attempt to measure the change for one particular university, *University of Madras*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c627a961-3977-487a-ac99-0c47fcd78198",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6947bae9-c28e-43c2-b930-dd8d67b4f618",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q9-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "# Filter the rows for \"University of Madras\" in the dataset\n",
    "madras_2021 = rankings[(rankings[\"Institution\"] == \"University of Madras\") & (rankings[\"Year\"] == 2021)]\n",
    "madras_2022 = rankings[(rankings[\"Institution\"] == \"University of Madras\") & (rankings[\"Year\"] == 2022)]\n",
    "\n",
    "# Extract the rankings for 2021 and 2022 using .iloc[0]\n",
    "rank_2021 = madras_2021[\"World Rank\"].iloc[0]\n",
    "rank_2022 = madras_2022[\"World Rank\"].iloc[0]\n",
    "\n",
    "# Calculate the absolute difference\n",
    "absolute_diff_madras = abs(rank_2021 - rank_2022)\n",
    "\n",
    "# Display the absolute difference\n",
    "print(absolute_diff_madras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6a1813e-fc2c-4e5b-9595-373c6b60a897",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q9...\n",
      "59\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q9\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe750abd-7f97-4372-a354-e14567ff2f84",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 10: Create a Series with the absolute difference in ranks for *\"University of Madras\"* between *2021* and *2022*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a60ea-92fb-4c17-bd2d-ffbb567ebef4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Create a **dictionary** with the keys as the **strings** `Institution` and `Absolute Change`. The values should be the relevant values for *University of Madras*. You should use the `absolute_diff_madras` variable from the previous question. Then, convert this **dictionary** to a **Series**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6cc50f-c635-41ae-abe1-b5783d491cf2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43eb97a8-c8dc-41fc-86df-17269f3da7bf",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q10-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Institution        University of Madras\n",
      "Absolute Change                      59\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the dictionary with Institution and Absolute Change\n",
    "madras_dict = {\n",
    "    \"Institution\": \"University of Madras\",\n",
    "    \"Absolute Change\": absolute_diff_madras\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a pandas Series\n",
    "madras_series = pd.Series(madras_dict)\n",
    "\n",
    "# Display the Series\n",
    "print(madras_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f578225-7401-4c3d-aa43-2b9c4e827f9b",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q10...\n",
      "Institution        University of Madras\n",
      "Absolute Change                      59\n",
      "dtype: object\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q10\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70145a23-139b-4098-b697-a995bc1b474f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 11: Create the change_in_rankings DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c4b958-92ac-490a-a2f1-d5314588a3f4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Create a **DataFrame** `change_in_rankings` with just 2 columns, `Institution` and `Absolute Change` where **each** university is only featured once. If the institution is **not** present in the rankings of **both** years, we will just ignore it.\n",
    "\n",
    "The institutions should be **sorted** in *increasing* order of their **absolute change**. For institutions with the **same** absolute change, sort them *alphabetically* by their **names**.\n",
    "\n",
    "**Warning:** Even if your code is optimal, this cell may take a few seconds to run. However, if it takes much longer than that (say, if it takes 30 seconds or longer), then you will **need** to optimize your code so it runs faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ca395-1bf8-4aca-b591-9163faf92eb2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "993104a4-1c18-4295-9fc1-194cb4b0d03c",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q11-code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Institution</th>\n",
       "      <th>Absolute Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>Ben-Gurion University of the Negev</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Brown University</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>Carleton University</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>Central Queensland University</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>Complutense University of Madrid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>Sechenov University</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>Duy Tân University</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>Huzhou University</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SRM Institute of Science and Technology</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>Homi Bhabha National Institute</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1928 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Institution  Absolute Change\n",
       "1310       Ben-Gurion University of the Negev                0\n",
       "886                          Brown University                0\n",
       "1628                      Carleton University                0\n",
       "1684            Central Queensland University                0\n",
       "1289         Complutense University of Madrid                0\n",
       "...                                       ...              ...\n",
       "1878                      Sechenov University              335\n",
       "1410                       Duy Tân University              342\n",
       "777                         Huzhou University              398\n",
       "96    SRM Institute of Science and Technology              405\n",
       "1358           Homi Bhabha National Institute              674\n",
       "\n",
       "[1928 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to store dictionaries for each institution\n",
    "institutions_data = []\n",
    "\n",
    "# Loop through the list of unique institutions\n",
    "for institution in institutions_list:\n",
    "    # Filter the DataFrame for the current institution\n",
    "    institution_data = rankings[rankings[\"Institution\"] == institution]\n",
    "    \n",
    "    # Get the list of years in which the institution appears\n",
    "    years = institution_data[\"Year\"].tolist()\n",
    "    \n",
    "    # Skip if the institution is not present in both 2021 and 2022\n",
    "    if 2021 not in years or 2022 not in years:\n",
    "        continue\n",
    "    \n",
    "    # Extract the World Rank for 2021 and 2022\n",
    "    rank_2021 = institution_data[institution_data[\"Year\"] == 2021][\"World Rank\"].iloc[0]\n",
    "    rank_2022 = institution_data[institution_data[\"Year\"] == 2022][\"World Rank\"].iloc[0]\n",
    "    \n",
    "    # Calculate the absolute change in ranking\n",
    "    absolute_change = abs(rank_2021 - rank_2022)\n",
    "    \n",
    "    # Create a dictionary with Institution and Absolute Change\n",
    "    institution_dict = {\n",
    "        \"Institution\": institution,\n",
    "        \"Absolute Change\": absolute_change\n",
    "    }\n",
    "    \n",
    "    # Append the dictionary to the list\n",
    "    institutions_data.append(institution_dict)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "change_in_rankings = pd.DataFrame(institutions_data)\n",
    "\n",
    "# Sort the DataFrame by Absolute Change (ascending) and Institution (alphabetical order for ties)\n",
    "change_in_rankings = change_in_rankings.sort_values(by=[\"Absolute Change\", \"Institution\"])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "change_in_rankings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7685738-c9ba-433f-93c8-cfd722900f47",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q11...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q11\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70d910-c067-4d45-9804-ac2a1c579553",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Section 6: BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4549140-327b-4716-a386-6b66cd0b4301",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As mentioned in Section 2, the `rankings.json` file was created by parsing HTML content on the Web, specifically the web pages listed below.\n",
    "\n",
    "* https://cs220.cs.wisc.edu/projects/data/2021.html\n",
    "* https://cs220.cs.wisc.edu/projects/data/2022.html\n",
    "* https://cs220.cs.wisc.edu/projects/data/2023.html\n",
    "\n",
    "Now, let's write a function to do this ourselves. We will use the `BeautifulSoup` module to scrape web pages and extract information. It is recommended that you review the relevant lecture code here: [Mike](https://canvas.wisc.edu/courses/427075/files/folder/Mikes_Lecture_Notes/lec31_web_3), [Louis](https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-lecture-material/-/tree/main/s24/Louis_Lecture_Notes/31_Web3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db53d9e-5b4e-4c76-ae0f-79cfb259be86",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Download `2021.html`, `2022.html` and `2023.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9de94ba-2e05-4ccd-950d-1e082a33c442",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use the `download` function you previously created to download the contents of each of the URLs above and save them into files. Name the files `2021.html`, `2022.html` and `2023.html` based on the respective URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30457de6-c318-4709-b3d1-b6b61f96e8a7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b7c8ab1-15ad-42b5-81d7-f47629291935",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-downloads-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021.html created!\n",
      "2022.html created!\n",
      "2023.html created!\n"
     ]
    }
   ],
   "source": [
    "# Use the 'download' function to download and save the HTML files\n",
    "message_2021 = download(\"https://cs220.cs.wisc.edu/projects/data/2021.html\", \"2021.html\")\n",
    "message_2022 = download(\"https://cs220.cs.wisc.edu/projects/data/2022.html\", \"2022.html\")\n",
    "message_2023 = download(\"https://cs220.cs.wisc.edu/projects/data/2023.html\", \"2023.html\")\n",
    "\n",
    "# Print the messages returned by the 'download' function\n",
    "print(message_2021)\n",
    "print(message_2022)\n",
    "print(message_2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4eb3faad-44ad-49ca-ac14-636124f93c87",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-downloads...\n",
      "2021.html already exists!\n",
      "2022.html already exists!\n",
      "2023.html already exists!\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-downloads\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682864b4-9136-49a1-a864-7cac67c9f7d3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Note that the cell above only checked if the files had been created, and **not** whether they contain the correct data. You must check that yourself. Check your `lab-p12` directory in Finder (Mac) / Explorer (Windows). It should now have a files called `2021.html`, `2022.html` and `2023.html`. **Manually open** these files and confirm they contain the contents of the respective page:\n",
    "* [2021.html](https://cs220.cs.wisc.edu/projects/data/2021.html)\n",
    "* [2022.html](https://cs220.cs.wisc.edu/projects/data/2022.html)\n",
    "* [2023.html](https://cs220.cs.wisc.edu/projects/data/2023.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876c202a-e18d-4656-aca2-892f1810a351",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 12: Read `2021.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278dd4d-ef1d-48cb-9af7-f94fe8a02d71",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "First, read the contents of the file `2021.html`.\n",
    "\n",
    "**Hint:** If you get a `UnicodeDecodeError`, make sure all your calls to `open` have the keyword argument `encoding=\"utf-8\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6014c42-ff26-44a5-907a-ea27b3677e04",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbd8b0b0-3d13-418e-b8f3-942f99bed0bd",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q12-code"
    ]
   },
   "outputs": [],
   "source": [
    "# Open the file \"2021.html\", read its content, and store it in the variable 'file_content_2021'\n",
    "with open(\"2021.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    file_content_2021 = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7decd75-00d4-425d-a06e-cb6b88c2c815",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q12...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q12\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3311415-028b-48b2-ae2b-6b24d2d3e215",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 13: Initialize `BeautifulSoup` object instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627af2eb-0335-47a5-9d8d-130a74ac6af0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use the variable `file_content_2021` defined in Question 12 to create a `BeautifulSoup` object instance. You can review the relevant lecture code here: [Mike](https://canvas.wisc.edu/courses/397655/files/folder/Mikes_Lecture_Notes/lec31_web_3), [Louis](https://git.doit.wisc.edu/cdis/cs/courses/cs220/cs220-lecture-material/-/tree/main/s24/Louis_Lecture_Notes/31_Web3).\n",
    "\n",
    "Note: the grader for this question only tests whether the variable you created is a `BeautifulSoup` object. It does not check if the variable has the correct value. We will check the correctness of the variable by finding certain tags in the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f384ba33-2fbd-404a-a0dc-b531024c45d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0350bbd-2632-4637-8fe4-95bf6a48922f",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q13-code"
    ]
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Create a BeautifulSoup object instance\n",
    "soup_2021 = BeautifulSoup(file_content_2021, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "290323b1-b481-45c0-bc40-85d7fc06f79a",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q13...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q13\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf96f9-a0b5-4510-8a2e-301a5aa2351e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 14: Find the `table` element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e760d1-c558-48c1-aaa2-69b2eb1ade20",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The webpage has a `table` containing all the data we're trying to extract. Write the code to **find** this element. Use the variable `soup_2021` defined in Question 13.\n",
    "\n",
    "Note: the grader for this question only tests whether you found a tag from the `BeautifulSoup` object defined in Question 13. It does not check if you found the right tag. We will check the correctness of the table by further finding all its header cells in Question 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede7d70e-469a-47c6-90c3-99c67da1b5e7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "190bb845-6344-4b6f-8684-d49aad3e2a25",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q14-code"
    ]
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Open and read the content of \"2021.html\"\n",
    "with open(\"2021.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    file_content_2021 = file.read()\n",
    "\n",
    "# Step 2: Create a BeautifulSoup object\n",
    "soup_2021 = BeautifulSoup(file_content_2021, \"html.parser\")\n",
    "\n",
    "# Step 3: Find the table element in the BeautifulSoup object\n",
    "table_2021 = soup_2021.find(\"table\")\n",
    "\n",
    "# The variable 'table_2021' now contains the first <table> element from the HTML file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db2ffc15-10c1-4f41-a8b9-8a0a3678235b",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q14...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q14\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f2d71-4144-4a61-b341-2f13509dde7a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 15: Find all `th` tags, to parse the table header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de280f-a69c-4d78-a29f-85220802a6d7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use the `table_2021` defined in Question 14 to find the table header. Remember that the table header is represented by the `th` tag. You can use the `find_all` function to find all instances of the given tag in a `BeautifulSoup` object.\n",
    "\n",
    "**Hint**: The **header** should be a **list** of elements, that can be obtained by using the `get_text` method for each `th` element in the table. You may also find list comprehension useful here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c833c5ff-3df0-4f29-af17-fc3e4e845a5f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08efb5c7-fdde-48ef-a782-ce649e9d587a",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q15-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['World Rank', 'Institution', 'Country', 'National Rank', 'Education Rank', 'Employability Rank', 'Faculty Rank', 'Research Rank', 'Score']\n"
     ]
    }
   ],
   "source": [
    "# Find all <th> tags in the table\n",
    "th_tags = table_2021.find_all(\"th\")\n",
    "\n",
    "# Extract the text content of each <th> tag\n",
    "header_2021 = [th.get_text(strip=True) for th in th_tags]\n",
    "\n",
    "# Display the header\n",
    "print(header_2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0e03816-c299-4586-b681-82ffd00ccf0f",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q15...\n",
      "['World Rank', 'Institution', 'Country', 'National Rank', 'Education Rank', 'Employability Rank', 'Faculty Rank', 'Research Rank', 'Score']\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q15\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a56ce4-965b-4099-b685-be4031202e01",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 16: Build row dictionary for one row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e951efe-eea7-4cdf-abfe-1205545e36c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Scrape the **second** row (the first one is the **header**!) of the `table`, convert the data to the appropriate **data types**, and populate the data into a **dictionary**. The **keys** of the dictionary **must** be the columns in the **DataFrame**. You **may** *hardcode* these **keys**, however it would be more efficient to use the variable `header_2021` obtained in the previous Question.\n",
    "\n",
    "**Hint**: Rows can be found by locating the `tr` elements in the table. After identifying the second row of the table, try to figure out which tag separates the different columns.\n",
    "\n",
    "The required data types for each column is:\n",
    "\n",
    "|**Column Name**|**Data Type**|\n",
    "|---------------|-------------|\n",
    "|`World Rank`|**int**|\n",
    "|`Institution`|**str**|\n",
    "|`Country`|**str**|\n",
    "|`National Rank`|**int**|\n",
    "|`Education Rank`|**int**|\n",
    "|`Employability Rank`|**int**|\n",
    "|`Faculty Rank`|**int**|\n",
    "|`Research Rank`|**int**|\n",
    "|`Score`|**float**|\n",
    "\n",
    "You can **compare** your output with the data in `rankings.json`, to confirm whether you have parsed the file correctly (note that you do **not** yet have to implement the `Year` column in your **dictionary**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6327e-4eab-4e10-ac70-7518fe1da344",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4aff8151-125f-490c-8310-22fa2c613dc0",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q16-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'World Rank': 1, 'Institution': 'Harvard University', 'Country': 'USA', 'National Rank': 1, 'Education Rank': 1, 'Employability Rank': 1, 'Faculty Rank': 1, 'Research Rank': 1, 'Score': 100.0}\n"
     ]
    }
   ],
   "source": [
    "# find the second row of the table, parse it, and store the result in the variable 'row_dict'\n",
    "rows = table_2021.find_all(\"tr\")\n",
    "second_row = rows[1]\n",
    "cells = second_row.find_all(\"td\")\n",
    "row_dict = {}\n",
    "column_types = {\n",
    "    \"World Rank\": int, \n",
    "    \"Institution\": str,\n",
    "    \"Country\": str,\n",
    "    \"National Rank\": int,\n",
    "    \"Education Rank\": int,\n",
    "    \"Employability Rank\": int,\n",
    "    \"Faculty Rank\": int,\n",
    "    \"Research Rank\": int,\n",
    "    \"Score\": float\n",
    "}\n",
    "\n",
    "for index, cell in enumerate(cells):\n",
    "    column_name = header_2021[index]\n",
    "    cell_value = cell.get_text().strip()\n",
    "    if cell_value == \"-\":\n",
    "        row_dict[column_name] = None\n",
    "    else:\n",
    "        row_dict[column_name] = column_types[column_name](cell_value)\n",
    "        \n",
    "print(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb965e4c-dc1f-4196-97a1-fb33ac54d05c",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q16...\n",
      "{'World Rank': 1, 'Institution': 'Harvard University', 'Country': 'USA', 'National Rank': 1, 'Education Rank': 1, 'Employability Rank': 1, 'Faculty Rank': 1, 'Research Rank': 1, 'Score': 100.0}\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q16\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b304d03b-12e1-44d8-9257-c5df2907a1a4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 17: Build list of all row dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c8437-3891-4d6b-90b9-62dad0ebb6dd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Continuing from Question 16, scrape **all** rows in `table_2021`, **convert** data to appropriate types, and populate data into a row **dictionary** and append row all dictionaries to a **list**. You can use a loop to extract all rows and populate the list.\n",
    "\n",
    "**Important**:\n",
    "* Some fields in the dataset have **missing** values, represented simply as `\"-\"`. Such **missing** values should be replaced by `None` in your **dictionary**.\n",
    "* Do NOT display the entire list as it can be very long and cause the notebook to run slow. You can print out the first few elements of the list to check if it matches the table inside the `2021.html` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5897dc-f8b3-47c5-bb43-554f3be040be",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cdf7f4ac-6e90-418a-90cd-c7a9d6d775b7",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q17-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "[{'World Rank': 1, 'Institution': 'Harvard University', 'Country': 'USA', 'National Rank': 1, 'Education Rank': 1, 'Employability Rank': 1, 'Faculty Rank': 1, 'Research Rank': 1, 'Score': 100.0}, {'World Rank': 2, 'Institution': 'Massachusetts Institute of Technology', 'Country': 'USA', 'National Rank': 2, 'Education Rank': 4, 'Employability Rank': 12, 'Faculty Rank': 2, 'Research Rank': 8, 'Score': 96.7}, {'World Rank': 3, 'Institution': 'Stanford University', 'Country': 'USA', 'National Rank': 3, 'Education Rank': 10, 'Employability Rank': 4, 'Faculty Rank': 3, 'Research Rank': 2, 'Score': 95.1}, {'World Rank': 4, 'Institution': 'University of Cambridge', 'Country': 'United Kingdom', 'National Rank': 1, 'Education Rank': 3, 'Employability Rank': 25, 'Faculty Rank': 4, 'Research Rank': 10, 'Score': 94.1}, {'World Rank': 5, 'Institution': 'University of Oxford', 'Country': 'United Kingdom', 'National Rank': 2, 'Education Rank': 7, 'Employability Rank': 27, 'Faculty Rank': 9, 'Research Rank': 4, 'Score': 93.3}]\n"
     ]
    }
   ],
   "source": [
    "# build a list of row dictionaries using the algorithm in Question 16, and store the result in 'rows_2021'\n",
    "rows_2021 = []\n",
    "all_rows = table_2021.find_all(\"tr\")[1:]\n",
    "column_types = {\n",
    "    \"World Rank\": int, \n",
    "    \"Institution\": str,\n",
    "    \"Country\": str,\n",
    "    \"National Rank\": int,\n",
    "    \"Education Rank\": int,\n",
    "    \"Employability Rank\": int,\n",
    "    \"Faculty Rank\": int,\n",
    "    \"Research Rank\": int,\n",
    "    \"Score\": float\n",
    "}\n",
    "\n",
    "for row in all_rows:\n",
    "    row_dict = {}\n",
    "    cells = row.find_all(\"td\")\n",
    "    if len(cells) != len(header_2021):\n",
    "        continue\n",
    "    for index, cell in enumerate(cells):\n",
    "        column_name = header_2021[index]\n",
    "        cell_value = cell.get_text().strip()\n",
    "        if cell_value == \"-\":\n",
    "            row_dict[column_name] = None\n",
    "        else:\n",
    "            row_dict[column_name] = column_types[column_name](cell_value)\n",
    "    rows_2021.append(row_dict)\n",
    "print(len(rows_2021))\n",
    "print(rows_2021[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9e4b2f8-2d74-4859-be3e-4c0f945bd384",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q17...\n",
      "2000\n",
      "[{'World Rank': 1, 'Institution': 'Harvard University', 'Country': 'USA', 'National Rank': 1, 'Education Rank': 1, 'Employability Rank': 1, 'Faculty Rank': 1, 'Research Rank': 1, 'Score': 100.0}, {'World Rank': 2, 'Institution': 'Massachusetts Institute of Technology', 'Country': 'USA', 'National Rank': 2, 'Education Rank': 4, 'Employability Rank': 12, 'Faculty Rank': 2, 'Research Rank': 8, 'Score': 96.7}, {'World Rank': 3, 'Institution': 'Stanford University', 'Country': 'USA', 'National Rank': 3, 'Education Rank': 10, 'Employability Rank': 4, 'Faculty Rank': 3, 'Research Rank': 2, 'Score': 95.1}, {'World Rank': 4, 'Institution': 'University of Cambridge', 'Country': 'United Kingdom', 'National Rank': 1, 'Education Rank': 3, 'Employability Rank': 25, 'Faculty Rank': 4, 'Research Rank': 10, 'Score': 94.1}, {'World Rank': 5, 'Institution': 'University of Oxford', 'Country': 'United Kingdom', 'National Rank': 2, 'Education Rank': 7, 'Employability Rank': 27, 'Faculty Rank': 9, 'Research Rank': 4, 'Score': 93.3}]\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q17\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793ac417-e2f3-41c4-959c-e02ff0e49d7c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Function 2: `parse.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4816d05d-9a0b-4adf-ad17-37304be3b9c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "From question 12-17, we've succesfully located the table inside `2021.html` and parsed the table into a list of dictionaries. Naturally, we would want to generalize this process into a function so that it can work on the other html files, not just `2021.html`. This function `parse_html` should take in a `filename` as **input** and **return** a **list** of **dictionaries**, with each **dictionary** representing a **row** in the dataset.\n",
    "\n",
    "Additionally, we **also** want to include the **key** `Year` to all our **dictionaries**. The `Year` value is **not** present in the dataset, so you need extract this value from the `filename`.\n",
    "\n",
    "Finally, if you are having trouble passing the check for this function, move on to question 18, 19, and 20. Each question tests your `parse_html` function with increasingly difficult html files. Each test also comes with useful hints that can help you debug `parse_html`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c6cf1-40b5-417e-af22-58a281f97553",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "680b27c5-8a22-4aed-ad9e-e34937a44f92",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-function-parse_html-code"
    ]
   },
   "outputs": [],
   "source": [
    "def parse_html(filename):\n",
    "    '''parse_html(filename) parses an HTML file and \n",
    "    returns a list of dictionaries containing the tabular data'''\n",
    "    \n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        file_content = file.read()\n",
    "    soup = BeautifulSoup(file_content, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "    if not table:\n",
    "        return []  \n",
    "\n",
    "    header_tags = table.find_all(\"th\")\n",
    "    header = [tag.get_text().strip() for tag in header_tags]\n",
    "\n",
    "    year = int(filename.split(\"/\")[-1].split(\".\")[0])\n",
    "\n",
    "    column_types = {\n",
    "        \"World Rank\": int, \n",
    "        \"Institution\": str,\n",
    "        \"Country\": str,\n",
    "        \"National Rank\": int,\n",
    "        \"Education Rank\": int,\n",
    "        \"Employability Rank\": int,\n",
    "        \"Faculty Rank\": int,\n",
    "        \"Research Rank\": int,\n",
    "        \"Score\": float\n",
    "    }\n",
    "    \n",
    "    rows_list = []\n",
    "    all_rows = table.find_all(\"tr\")[1:]  \n",
    "    for row in all_rows:\n",
    "        row_dict = {}\n",
    "        cells = row.find_all(\"td\")\n",
    "        if len(cells) != len(header):\n",
    "            continue  \n",
    "        for index, cell in enumerate(cells):\n",
    "            column_name = header[index]\n",
    "            cell_value = cell.get_text().strip()\n",
    "\n",
    "            if column_name == \"World Rank\":\n",
    "                cell_value = cell_value.split()[0]  \n",
    "                cell_value = \"\".join(c for c in cell_value if c.isdigit())  \n",
    "            \n",
    "            if column_name == \"Institution\":\n",
    "                cell_value = cell_value.split(\"\\n\")[0].strip()\n",
    "\n",
    "            if column_name in [\"National Rank\", \"Education Rank\", \"Employability Rank\", \n",
    "                               \"Faculty Rank\", \"Research Rank\"]:\n",
    "                cell_value = \"\".join(c for c in cell_value if c.isdigit())\n",
    "            elif column_name == \"Score\":\n",
    "                cell_value = \"\".join(c for c in cell_value if c.isdigit() or c == \".\")\n",
    "\n",
    "            if cell_value == \"\":\n",
    "                row_dict[column_name] = None\n",
    "            else:\n",
    "                try:\n",
    "                    row_dict[column_name] = column_types[column_name](cell_value)\n",
    "                except ValueError:\n",
    "                    row_dict[column_name] = cell_value \n",
    "\n",
    "        row_dict[\"Year\"] = year\n",
    "        rows_list.append(row_dict)\n",
    "    \n",
    "    return rows_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "93842390-efe9-47fc-a5d1-b77a97931a56",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-function-parse_html...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-function-parse_html\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420a9b4-b84e-4f31-ac26-8e3f82591849",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 18: Parse `2021.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066ed7c5-ed65-439e-b72a-5cb8cbba9500",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We will now attempt to read `2021.html` using the `parse_html` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa66cf70-f6f0-4219-9b4b-e0a03c7d2a84",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b681a09-916a-4431-a8df-8f0f384fbf2d",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q18-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'World Rank': 1, 'Institution': 'Harvard University', 'Country': 'USA', 'National Rank': 1, 'Education Rank': 1, 'Employability Rank': 1, 'Faculty Rank': 1, 'Research Rank': 1, 'Score': 100.0, 'Year': 2021}, {'World Rank': 2, 'Institution': 'Massachusetts Institute of Technology', 'Country': 'USA', 'National Rank': 2, 'Education Rank': 4, 'Employability Rank': 12, 'Faculty Rank': 2, 'Research Rank': 8, 'Score': 96.7, 'Year': 2021}, {'World Rank': 3, 'Institution': 'Stanford University', 'Country': 'USA', 'National Rank': 3, 'Education Rank': 10, 'Employability Rank': 4, 'Faculty Rank': 3, 'Research Rank': 2, 'Score': 95.1, 'Year': 2021}]\n"
     ]
    }
   ],
   "source": [
    "# Parse the 2021.html file using the parse_html function\n",
    "parsed_2021 = parse_html(\"2021.html\")\n",
    "\n",
    "# Display the first 3 rows of the parsed data\n",
    "print(parsed_2021[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0582b6c-d99b-410b-b42d-2428285a938b",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q18...\n",
      "[{'World Rank': 1, 'Institution': 'Harvard University', 'Country': 'USA', 'National Rank': 1, 'Education Rank': 1, 'Employability Rank': 1, 'Faculty Rank': 1, 'Research Rank': 1, 'Score': 100.0, 'Year': 2021}, {'World Rank': 2, 'Institution': 'Massachusetts Institute of Technology', 'Country': 'USA', 'National Rank': 2, 'Education Rank': 4, 'Employability Rank': 12, 'Faculty Rank': 2, 'Research Rank': 8, 'Score': 96.7, 'Year': 2021}, {'World Rank': 3, 'Institution': 'Stanford University', 'Country': 'USA', 'National Rank': 3, 'Education Rank': 10, 'Employability Rank': 4, 'Faculty Rank': 3, 'Research Rank': 2, 'Score': 95.1, 'Year': 2021}]\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q18\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ba2b3-03fa-4919-9962-009fc3778951",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "If you fail any of the checks above, go back and verify that you typecast properly. You could also manually open `2021.html`, and visually identify why your code failed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1899b7-e8b5-4ef0-a4fd-fb32304adacd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 19: Parse `2022.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5c930-c90e-4467-80ec-695cfce3f69b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We will now attempt to read `2022.html` using the `parse_html` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70216685-f4c3-4f16-a3de-e866e551588e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df3cc586-f3d6-4585-b443-b683ed6026f8",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q19-code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'World Rank': 1,\n",
       "  'Institution': 'Harvard University',\n",
       "  'Country': 'USA',\n",
       "  'National Rank': 1,\n",
       "  'Education Rank': 1,\n",
       "  'Employability Rank': 1,\n",
       "  'Faculty Rank': 1,\n",
       "  'Research Rank': 1,\n",
       "  'Score': 100.0,\n",
       "  'Year': 2022},\n",
       " {'World Rank': 2,\n",
       "  'Institution': 'Massachusetts Institute of Technology',\n",
       "  'Country': 'USA',\n",
       "  'National Rank': 2,\n",
       "  'Education Rank': 4,\n",
       "  'Employability Rank': 12,\n",
       "  'Faculty Rank': 2,\n",
       "  'Research Rank': 7,\n",
       "  'Score': 96.7,\n",
       "  'Year': 2022},\n",
       " {'World Rank': 3,\n",
       "  'Institution': 'Stanford University',\n",
       "  'Country': 'USA',\n",
       "  'National Rank': 3,\n",
       "  'Education Rank': 11,\n",
       "  'Employability Rank': 4,\n",
       "  'Faculty Rank': 3,\n",
       "  'Research Rank': 2,\n",
       "  'Score': 95.1,\n",
       "  'Year': 2022}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell to test whether 'parse_html' has been defined properly\n",
    "\n",
    "parsed_2022 = parse_html(\"2022.html\")\n",
    "\n",
    "parsed_2022[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6bb0c2ee-3db4-4843-a773-47b3b3a28d4b",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q19...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q19\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05360946-3b1d-4436-b26e-78a5c1762925",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "It is **highly likely** that your code **failed the tests above**. To understand why,\n",
    "1. Take a look at the value of `parsed_2022[0]['Institution']`.\n",
    "2. **Manually open** `2022.html`, and **identify** what is going on there.\n",
    "\n",
    "Then, go back to the definition of `parse_html` and **modify** it, so that it can deal with this case here. It is completely up to you, how you deal with this case here, as long as you correctly identify just the name of the `Institution` for all universities.\n",
    "\n",
    "**Important**: While modifying `parse_html`, it is important that you do not break the function in such a way that it no longer works for `2021.html`. Your function **must** be able to read **both** `2021.html` and `2022.html`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fedef86-0dfe-415f-85ed-45ba41e57e47",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Lab Question 20:  Parse `2023.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0219da-ad5f-4b60-b7a0-d1c81c31702b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We will now attempt to read `2023.html` using the `parse_html` function. As above, make sure to manually open the `2023.html` file and verify your output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda9ff2-cac8-4627-9f04-c741139093ef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cbfb0298-7906-48b9-8b64-0301ff4d1ca1",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "lab-q20-code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'World Rank': 1,\n",
       "  'Institution': 'Harvard University',\n",
       "  'Country': 'USA',\n",
       "  'National Rank': 1,\n",
       "  'Education Rank': 1,\n",
       "  'Employability Rank': 1,\n",
       "  'Faculty Rank': 1,\n",
       "  'Research Rank': 1,\n",
       "  'Score': 100.0,\n",
       "  'Year': 2023},\n",
       " {'World Rank': 2,\n",
       "  'Institution': 'Massachusetts Institute of Technology',\n",
       "  'Country': 'USA',\n",
       "  'National Rank': 2,\n",
       "  'Education Rank': 4,\n",
       "  'Employability Rank': 12,\n",
       "  'Faculty Rank': 3,\n",
       "  'Research Rank': 9,\n",
       "  'Score': 96.7,\n",
       "  'Year': 2023},\n",
       " {'World Rank': 3,\n",
       "  'Institution': 'Stanford University',\n",
       "  'Country': 'USA',\n",
       "  'National Rank': 3,\n",
       "  'Education Rank': 11,\n",
       "  'Employability Rank': 4,\n",
       "  'Faculty Rank': 2,\n",
       "  'Research Rank': 2,\n",
       "  'Score': 95.2,\n",
       "  'Year': 2023}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell to test whether 'parse_html' has been defined properly\n",
    "\n",
    "parsed_2023 = parse_html(\"2023.html\")\n",
    "\n",
    "parsed_2023[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e619ff64-41e9-4e70-a59b-5b78f7576447",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for lab-q20...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"lab-q20\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e709c3ca-099d-4b6d-8e8e-47ae989d80d6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Lab Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49411c8d-c5b0-4479-8ac8-8611452b24ab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Great work! You are now ready to submit lab-p12.\n",
    " **Submit your p12.ipynb on Gradescope to the lab-p12 assignment**, like usual. Remember that the grades for the lab portion of the project and the actual assignment grade are independent. You will submit the same notebook (at different levels of completion) to two different assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f281eb3a-4701-4ba4-9867-06d5726be9bf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Project Portion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d18c1-ac8a-485f-bcd4-21554f42d7ce",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Learning Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2047d9-1301-4d80-8fe8-14093ac06e0c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In this project, you will demonstrate your ability to\n",
    "\n",
    "* read and write files,\n",
    "* create and use `Pandas DataFrames`,\n",
    "* use `BeautifulSoup` to parse web pages.\n",
    "\n",
    "Please go through the lab portion before working on this project. The lab introduces some useful techniques related to this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357bcdc-5a89-47a8-9250-e3db37342564",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h3 style=\"color:red\">Warning (Note on Academic Misconduct):</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44987a34-4d5b-4e68-8d1d-4fc7a6f9dbe7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**IMPORTANT**: **P12 and P13 are two parts of the same data analysis.** You **cannot** switch project partners between these two projects. That is if you partner up with someone for P12, you have to sustain that partnership until the end of P13. Now may be a good time to review [our course policies](https://cs220.cs.wisc.edu/f24/syllabus.html).\n",
    "\n",
    "Under any circumstances, **no more than two students are allowed to work together on a project** as mentioned in the course policies. If your code is flagged by our code similarity detection tools, **both partners will be responsible** for sharing/copying the code, even if the code is shared/copied by one of the partners with/from other non-partner student(s). Note that each case of plagiarism will be reported to the Dean of Students with a zero grade on the project. **If you think that someone cannot be your project partner then don’t make that student your lab partner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a36343-96bc-4f1f-a5da-f86a56821002",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05331e9c-4c91-4b64-ae31-82aa52d482c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For this project, you're going to analyze World University Rankings!\n",
    "\n",
    "Specifically, you're going to use Pandas to analyze various statistics of the top ranked universities across the world, over the last three years.\n",
    "\n",
    "**Important Warning:** Do **not** download any of the other `json` or `html` files manually (you **must** write Python code to download these automatically, as in Lab-P12). When we run the autograder, the other files such as `rankings.json`, `2021.html`, `2022.html`, `2023.html` will **not** be in the directory. So, unless your `p12.ipynb` downloads these files, the Gradescope autograder will **deduct** points from your public score. More details can be found in the **Setup** section of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4056a22-14df-479b-9e61-9279f62901e1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e045f11-c8e4-4fb7-9cf0-aa47fd0f6325",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For this project, we will be analyzing statistics about world university rankings adapted from [here](https://cwur.org/). These are the specific webpages that we extracted the data from:\n",
    "\n",
    "* https://cwur.org/2020-21.php\n",
    "* https://cwur.org/2021-22.php\n",
    "* https://cwur.org/2023.php\n",
    "\n",
    "Later in the project, you will be scraping these webpages and extracting the data yourself. Since we don't want all of you bombarding these webpages with requests, we have made snapshots of these webpages, and hosted them on GitLab. You can find the snapshots here:\n",
    "\n",
    "* https://cs220.cs.wisc.edu/projects/data/2021.html\n",
    "* https://cs220.cs.wisc.edu/projects/data/2022.html\n",
    "* https://cs220.cs.wisc.edu/projects/data/2023.html\n",
    "\n",
    "We have also tweaked the snapshots a little, to streamline the process of data extraction for you. You will be extracting the data from these three html pages and analyzing them. However, to make the start of the project a little easier, we have already parsed the files for you! We have gathered the data from these html files, and collected them in a single json file, which can be found here:\n",
    "\n",
    "* https://cs220.cs.wisc.edu/projects/data/rankings.json\n",
    "\n",
    "You will work with this json file for most of this project. At the end of this project, you will generate an identical json file by parsing the html files yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c6495a-84e5-46bc-8b61-c56c462466ea",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Project Requirements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02dc70a-c8d9-46ef-b24a-b0794497655e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You **may not** hardcode indices in your code. You **may not** manually download **any** files for this project, unless you are **explicitly** told to do so. For all other files, you **must** use the `download` function to download the files.\n",
    "\n",
    "**Store** your final answer for each question in the **variable specified for each question**. This step is important because Otter grades your work by comparing the value of this variable against the correct answer.\n",
    "\n",
    "For some of the questions, we'll ask you to write (then use) a function to compute the answer. If you compute the answer **without** creating the function we ask you to write, the Gradescope autograder will **deduct** points from your public score, even if the way you did it produced the correct answer.\n",
    "\n",
    "#### Required Functions:\n",
    "- `download`\n",
    "- `parse_html`\n",
    "\n",
    "In this project, you will also be required to define certain **data structures**. If you do not create these data structures exactly as specified, the Gradescope autograder will **deduct** points from your public score, even if the way you did it produced the correct answer.\n",
    "\n",
    "#### Required Data Structures:\n",
    "- `rankings`\n",
    "- `year_2021_ranking_df`\n",
    "- `year_2022_ranking_df`\n",
    "- `year_2023_ranking_df`\n",
    "- `institutions_df`\n",
    "\n",
    "In addition, you are also **required** to follow the requirements below:\n",
    "* **Avoid using loops to iterate over pandas dataframes and instead use boolean indexing.**\n",
    "* Do **not** use `loc` to look up data in **DataFrames** or **Series**, unless you are explicitly told to do so. You are **allowed** to use `iloc`.\n",
    "* Do **not** use **absolute** paths such as `C://mdoescher//cs220//p12`. You may **only** use **relative paths**.\n",
    "* Do **not** leave irrelevant output or test code that we didn't ask for.\n",
    "* **Avoid** calling **slow** functions multiple times within a loop.\n",
    "* Do **not** define multiple functions with the same name or define multiple versions of one function with different names. Just keep the best version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7068dfb-3751-46d4-a5fa-92cdde30dd2f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Section 1: Exploring `rankings.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e13dca-866b-439c-aab9-b1946346b08e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Download `rankings.json` and create `rankings` Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747fc2b-03fe-48df-abe9-e89688eae6a8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use `download` to pull the data from here (**do not manually download**): https://cs220.cs.wisc.edu/projects/data/rankings.json and store it in the file `rankings.json`. Since you already worked with this same file in the lab you should already have `rankings.json`, but just incase you should call the `download` function again. Once you are sure you have the file, create a Dataframe `rankings` from this file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478921d-e118-4822-874f-5a318ff2c49b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49ad233b-c429-415e-9cfa-fad8018b6328",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "download-rankings-code"
    ]
   },
   "outputs": [],
   "source": [
    "# use the 'download' function to download the data from the webpage\n",
    "url = \"https://cs220.cs.wisc.edu/projects/data/rankings.json\"\n",
    "filename = \"rankings.json\"\n",
    "download(url, filename)\n",
    "# to the file 'rankings.json'\n",
    "rankings = pd.read_json(filename)\n",
    "\n",
    "# open 'rankings.json' with pd.read_json('rankings.json') and store in the variable 'rankings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e693b06-6442-46dc-8292-b79ed21c5c51",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for download-rankings...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"download-rankings\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e954ad2-de21-453a-a82b-d8269e96944b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 1: How **many** countries do we have in our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb168c3-a2b4-4862-b8ba-9a253996f8bf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be an **int** representing the number of *unique* countries in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b70fa85-9d4f-46ae-acbf-ff387b0a07e3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ecedf75-ec0e-4dbd-a0bd-f2a93723b338",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q1-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'num_countries', then display it\n",
    "num_countries = rankings[\"Country\"].nunique()\n",
    "print(num_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "db40c861-6db7-4cc3-9e95-5555db7136e9",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q1...\n",
      "98\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q1\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9bc1a3-4339-446f-ab45-79902daaa808",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 2: Generate a `pandas` **DataFrame** containing **all** the statistics of the **highest-ranked** institution based on `World Rank` across all the years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8adbc7-fc25-43a0-a4ca-6a24b9338edd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a pandas **DataFrame** with 3 rows and 10 columns. It **must** contain all the data for the institutions with `World Rank` of *1*. It **must** look like this:\n",
    "\n",
    "||**Year**|**World Rank**|**Institution**|**Country**|**National Rank**|**Education Rank**|**Employability Rank**|**Faculty Rank**|**Research Rank**|**Score**|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|**0**|2021|1|Harvard University|USA|1|1.0|1.0|1.0|1.0|100.0|\n",
    "|**2000**|2022|1|Harvard University|USA|1|1.0|1.0|1.0|1.0|100.0|\n",
    "|**4000**|2023|1|Harvard University|USA|1|1.0|1.0|1.0|1.0|100.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f24fe-a56a-4f00-92ee-cd2324d7be21",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66c702a9-f9bd-4f5c-b398-5f5f140b8590",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q2-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  World Rank         Institution Country  National Rank  \\\n",
      "0     2021           1  Harvard University     USA              1   \n",
      "2000  2022           1  Harvard University     USA              1   \n",
      "4000  2023           1  Harvard University     USA              1   \n",
      "\n",
      "      Education Rank  Employability Rank  Faculty Rank  Research Rank  Score  \n",
      "0                1.0                 1.0           1.0            1.0  100.0  \n",
      "2000             1.0                 1.0           1.0            1.0  100.0  \n",
      "4000             1.0                 1.0           1.0            1.0  100.0  \n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'highest_ranked', then display it\n",
    "highest_ranked = rankings[rankings[\"World Rank\"] ==1]\n",
    "print(highest_ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23da54f6-e8c4-450f-bdc6-01b0127d4801",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q2...\n",
      "      Year  World Rank         Institution Country  National Rank  \\\n",
      "0     2021           1  Harvard University     USA              1   \n",
      "2000  2022           1  Harvard University     USA              1   \n",
      "4000  2023           1  Harvard University     USA              1   \n",
      "\n",
      "      Education Rank  Employability Rank  Faculty Rank  Research Rank  Score  \n",
      "0                1.0                 1.0           1.0            1.0  100.0  \n",
      "2000             1.0                 1.0           1.0            1.0  100.0  \n",
      "4000             1.0                 1.0           1.0            1.0  100.0  \n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q2\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4bb090-40f4-499a-9db5-9171c29bd029",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 3: Generate a `pandas` **DataFrame** containing **all** the statistics of *University of Wisconsin–Madison*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c7116b-a982-422e-814e-d99077ecc786",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Hint**: The `–` symbol in the text above is not the regular hyphen (`-`) symbol. It is recommended that you just *copy/paste* the string `'University of Wisconsin–Madison'` into your code instead of typing it yourself.\n",
    "\n",
    "Your output **must** be a pandas **DataFrame** with 3 rows and 10 columns. It **must** look like this:\n",
    "\n",
    "||**Year**|**World Rank**|**Institution**|**Country**|**National Rank**|**Education Rank**|**Employability Rank**|**Faculty Rank**|**Research Rank**|**Score**|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|**24**|2021|25|University of Wisconsin–Madison|USA|19|33.0|97.0|29.0|32.0|87.3|\n",
    "|**2026**|2022|27|University of Wisconsin–Madison|USA|20|34.0|100.0|30.0|35.0|87.0|\n",
    "|**4027**|2023|28|University of Wisconsin–Madison|USA|20|36.0|102.0|30.0|41.0|87.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe9f9d-29c8-48a5-b7bf-2cd0f9a35b0f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "610f8052-7dc7-4bc9-ae90-a91a3b37a149",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q3-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  World Rank                      Institution Country  \\\n",
      "24    2021          25  University of Wisconsin–Madison     USA   \n",
      "2026  2022          27  University of Wisconsin–Madison     USA   \n",
      "4027  2023          28  University of Wisconsin–Madison     USA   \n",
      "\n",
      "      National Rank  Education Rank  Employability Rank  Faculty Rank  \\\n",
      "24               19            33.0                97.0          29.0   \n",
      "2026             20            34.0               100.0          30.0   \n",
      "4027             20            36.0               102.0          30.0   \n",
      "\n",
      "      Research Rank  Score  \n",
      "24             32.0   87.3  \n",
      "2026           35.0   87.0  \n",
      "4027           41.0   87.0  \n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'uw_madison', then display it\n",
    "uw_madison = rankings[rankings[\"Institution\"] == \"University of Wisconsin–Madison\"]\n",
    "print(uw_madison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0883d69-d188-4f84-82d5-9372bc1cd731",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q3...\n",
      "      Year  World Rank                      Institution Country  \\\n",
      "24    2021          25  University of Wisconsin–Madison     USA   \n",
      "2026  2022          27  University of Wisconsin–Madison     USA   \n",
      "4027  2023          28  University of Wisconsin–Madison     USA   \n",
      "\n",
      "      National Rank  Education Rank  Employability Rank  Faculty Rank  \\\n",
      "24               19            33.0                97.0          29.0   \n",
      "2026             20            34.0               100.0          30.0   \n",
      "4027             20            36.0               102.0          30.0   \n",
      "\n",
      "      Research Rank  Score  \n",
      "24             32.0   87.3  \n",
      "2026           35.0   87.0  \n",
      "4027           41.0   87.0  \n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q3\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0001dc2-3ff5-4532-a5f0-96a166c1b99d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 4: What is the `National Rank` of the *University of Wisconsin–Madison* in the `Year` *2023*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f258fb-e3e2-4f6f-a962-b4c39da1fed0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be an **int**. You **must** use **Boolean indexing** on the variable `uw_madison` (from the previous question) to answer this question.\n",
    "\n",
    "**Hint:** Use Boolean indexing on the DataFrame `uw_madison` to find the data for the year *2023*. You may then extract the `National Rank` column from the subset DataFrame. Finally, use `iloc` to lookup the value in the DataFrame which contains only one row and one column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2b365-2939-4aec-8d58-3a7fbd27b3b5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d6c517b-defb-40f5-8576-2245a95d0b5c",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q4-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "uw_madison_2023 = uw_madison[uw_madison[\"Year\"] == 2023]\n",
    "uw_madison_nat_rank = uw_madison_2023[\"National Rank\"].iloc[0]\n",
    "print(uw_madison_nat_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0aaf5857-1694-43b4-be18-5fb34948608c",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q4...\n",
      "20\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q4\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8f4fb-76e0-4194-bdde-7bb8c662112c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 5: What is the **average** `Score` of the *University of Wisconsin–Madison*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e638a5-9461-49db-82e8-cf2e9e2e20b1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **float**. You **must** use the variable `uw_madison` to answer this question.\n",
    "\n",
    "**Hint:** You **must** extract the `Score` column of the **DataFrame** `uw_madison` as a **Series**. You can find the **average** of  all the scores in a **Series** with the `Series.mean` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a453ef-a680-4e59-bc0f-55828d130506",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19787f5f-fc44-4e07-93e7-b93c85108d6a",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q5-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.10000000000001\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'uw_madison_avg_score', then display it\n",
    "uw_madison_avg_score = uw_madison[\"Score\"].mean()\n",
    "print(uw_madison_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "77316fb4-4685-4231-a856-28845ad0263c",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q5...\n",
      "87.10000000000001\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q5\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e5dd3-6429-4d71-a92b-f59fec431283",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 6: Generate a `pandas` **DataFrame** containing **all** the statistics of universities from the `Country` *Singapore* in the `Year` *2022*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd1a970-c66c-4cb8-a0b9-b65d975a3112",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a pandas **DataFrame** with 4 rows and 10 columns. It **must** look like this:\n",
    "\n",
    "||**Year**|**World Rank**|**Institution**|**Country**|**National Rank**|**Education Rank**|**Employability Rank**|**Faculty Rank**|**Research Rank**|**Score**|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| **2084** | 2022 | 85 | National University of Singapore | Singapore | 1 | 342.0 | 172.0 | NaN | 41.0 | 82.4 |\n",
    "| **2132** | 2022 | 133 | Nanyang Technological University | Singapore | 2 | NaN | 843.0 | NaN | 66.0 | 80.5 |\n",
    "| **3011** | 2022 | 1012 | Singapore University of Technology and Design | Singapore | 3 | NaN | NaN | NaN | 965.0 | 70.2 |\n",
    "| **3336** |   2022 |         1337 | Singapore Management University | Singapore | 4 | NaN | NaN | NaN | 1269.0 | 68.4 |\n",
    "\n",
    "**Hint:** When there are **multiple** conditions to filter a **DataFrame**, you can combine all the conditions with `&` as a logical operator between them. For example, you can extract the data for all the institutions with `Education Rank <= 10` and `Faculty Rank <= 10` with:\n",
    "\n",
    "```python\n",
    "rankings[(rankings[\"Education Rank\"] <= 10) & (rankings[\"Faculty Rank\"] <= 10)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629e7733-1d23-4f67-ad0d-f44f8a055903",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "29ef8bc5-97b4-49e3-8b92-cbfb19aa132c",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q6-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year  World Rank                                    Institution  \\\n",
      "2084  2022          85               National University of Singapore   \n",
      "2132  2022         133               Nanyang Technological University   \n",
      "3011  2022        1012  Singapore University of Technology and Design   \n",
      "3336  2022        1337                Singapore Management University   \n",
      "\n",
      "        Country  National Rank  Education Rank  Employability Rank  \\\n",
      "2084  Singapore              1           342.0               172.0   \n",
      "2132  Singapore              2             NaN               843.0   \n",
      "3011  Singapore              3             NaN                 NaN   \n",
      "3336  Singapore              4             NaN                 NaN   \n",
      "\n",
      "      Faculty Rank  Research Rank  Score  \n",
      "2084           NaN           41.0   82.4  \n",
      "2132           NaN           66.0   80.5  \n",
      "3011           NaN          965.0   70.2  \n",
      "3336           NaN         1269.0   68.4  \n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'singapore_inst', then display it\n",
    "singapore_inst = rankings[(rankings[\"Country\"] == \"Singapore\") & (rankings[\"Year\"] == 2022)]\n",
    "print(singapore_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9438d617-d30d-4260-8c70-830d204f4e5f",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q6...\n",
      "      Year  World Rank                                    Institution  \\\n",
      "2084  2022          85               National University of Singapore   \n",
      "2132  2022         133               Nanyang Technological University   \n",
      "3011  2022        1012  Singapore University of Technology and Design   \n",
      "3336  2022        1337                Singapore Management University   \n",
      "\n",
      "        Country  National Rank  Education Rank  Employability Rank  \\\n",
      "2084  Singapore              1           342.0               172.0   \n",
      "2132  Singapore              2             NaN               843.0   \n",
      "3011  Singapore              3             NaN                 NaN   \n",
      "3336  Singapore              4             NaN                 NaN   \n",
      "\n",
      "      Faculty Rank  Research Rank  Score  \n",
      "2084           NaN           41.0   82.4  \n",
      "2132           NaN           66.0   80.5  \n",
      "3011           NaN          965.0   70.2  \n",
      "3336           NaN         1269.0   68.4  \n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q6\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01397f07-32f2-43f9-a031-f01c55ac876b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 7:  In the `Year` *2022*, what was the **highest-ranked** institution in the `Country` *Germany*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374a9412-89ca-4d68-a64f-dd38039f8930",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **string** representing the **name** of this institution.\n",
    "\n",
    "**Hint:** The highest-ranked institution in *Germany* is the institution from Germany with a `National Rank` of *1*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32cf33-5a7f-47c4-8c42-d9a5e8c38a0a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8627008b-e96e-4da2-9fe4-8c6ac71ab024",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q7-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ludwig Maximilian University of Munich\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'german_best_name', then display it\n",
    "germany_2022 = rankings[(rankings[\"Country\"] == \"Germany\") & (rankings[\"Year\"] == 2022)]\n",
    "german_best_name = germany_2022[germany_2022[\"National Rank\"] == 1][\"Institution\"].iloc[0]\n",
    "print(german_best_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1bb1a2da-1f6f-40d0-bca8-f5284219c411",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q7...\n",
      "Ludwig Maximilian University of Munich\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q7\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785ed1af-3948-463d-9110-fe7dce8dd556",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 8: In the `Year` *2022*, list **all** the institutions in the *USA* that were ranked **better** than the highest-ranked institution in *Germany*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66e377d-aef1-4b0f-835b-88287cb40bda",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **list** containing the **names** of all universities from *USA* with a **better** `World Rank` than the institution `german_best_name` in the `Year` *2022*. By **better** ranked, we refer to institutions with a **lower** value under the `World Rank` column.\n",
    "\n",
    "**Hint:** You could store the entire row of the highest ranked institution from Germany in a different variable in Question 7, and use it to extract its `World Rank`. You could go back to your answer for Question 7, and edit it slightly to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142f9a2-55fc-4fe1-b33c-741dd909e0dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1929a9ed-32b6-47a4-8026-21a2075050c6",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q8-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harvard University', 'Massachusetts Institute of Technology', 'Stanford University', 'Princeton University', 'University of Chicago', 'Columbia University', 'University of Pennsylvania', 'California Institute of Technology', 'Yale University', 'University of California, Berkeley', 'Cornell University', 'University of Michigan, Ann Arbor', 'Johns Hopkins University', 'Northwestern University', 'University of California, Los Angeles', 'Duke University', 'University of Illinois at Urbana–Champaign', 'New York University', 'University of Washington', 'University of Wisconsin–Madison', 'University of Texas at Austin', 'University of California, San Diego', 'University of California, San Francisco', 'University of North Carolina at Chapel Hill', 'Dartmouth College']\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'us_better_than_german_best', then display it\n",
    "germany_2022 = rankings[(rankings[\"Country\"] == \"Germany\") & (rankings[\"Year\"] == 2022)]\n",
    "german_best = germany_2022[germany_2022[\"National Rank\"] ==1]\n",
    "german_best_world_rank = german_best[\"World Rank\"].iloc[0]\n",
    "us_better_than_german_best = rankings[\n",
    "    (rankings[\"Country\"] == \"USA\") &\n",
    "    (rankings[\"Year\"] == 2022) &\n",
    "    (rankings[\"World Rank\"] < german_best_world_rank)\n",
    "][\"Institution\"].tolist()\n",
    "\n",
    "print(us_better_than_german_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99083919-cd13-4c80-aeb1-c69095f2d285",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q8...\n",
      "['Harvard University', 'Massachusetts Institute of Technology', 'Stanford University', 'Princeton University', 'University of Chicago', 'Columbia University', 'University of Pennsylvania', 'California Institute of Technology', 'Yale University', 'University of California, Berkeley', 'Cornell University', 'University of Michigan, Ann Arbor', 'Johns Hopkins University', 'Northwestern University', 'University of California, Los Angeles', 'Duke University', 'University of Illinois at Urbana–Champaign', 'New York University', 'University of Washington', 'University of Wisconsin–Madison', 'University of Texas at Austin', 'University of California, San Diego', 'University of California, San Francisco', 'University of North Carolina at Chapel Hill', 'Dartmouth College']\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q8\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e01aae0-9a60-4c47-8dbe-55afbc02ce4d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 9: What is the **highest-ranked** institution based on `Education Rank` in *China* for the `Year` *2023*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc80f4-2769-4119-a9d0-27843930f241",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **string** representing the **name** of this institution. You may **assume** there is only one institution satisfying these requirements. By the **highest-ranked** institution, we refer to the institution with the **least** value under the `Education Rank` column.\n",
    "\n",
    "**Hint:** You can find the **minimum** value in a **Series** with the `Series.min` method. You can find the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.min.html) or by executing the line `help(pd.Series.min)` in a separate cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89a1a6-3de2-42e1-b92c-17b12b80f146",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b463fbd7-755c-4938-bfe3-df31ca73b6cf",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q9-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tsinghua University\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'china_highest_qoe', then display it\n",
    "china_2023 = rankings[(rankings[\"Country\"] == \"China\") & (rankings[\"Year\"] == 2023)]\n",
    "min_education_rank = china_2023[\"Education Rank\"].min()\n",
    "china_highest_qoe = china_2023[china_2023[\"Education Rank\"] == min_education_rank][\"Institution\"].iloc[0]\n",
    "print(china_highest_qoe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "37cee447-11a6-448b-a4df-d388850fa749",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q9...\n",
      "Tsinghua University\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q9\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678020b-0eab-4fc7-bb1d-d4081defcafd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 10: What are the **top** *five* **highest-ranked** institutions based on `Research Rank` in *India* for the `Year` *2022*?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc86f1b-6099-4a59-b0d0-78e8df4a012e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **list** of institutions **sorted** in *increasing* order of their `Research Rank`.\n",
    "\n",
    "**Hint:** For sorting a DataFrame based on the values of a particular column, you can use the `DataFrame.sort_values(by=\"column_name\")` method (where `column_name` is the column on which you want to sort). You can find the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html) or by executing the line `help(pd.Series.sort_values)` in a separate cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b371e31-d4cf-433f-9399-67393ed10f97",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2ee1d227-90da-453e-895b-930e5ea9bf27",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q10-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Indian Institute of Science', 'Tata Institute of Fundamental Research', 'Indian Institute of Technology Bombay', 'Indian Institute of Technology Madras', 'University of Delhi']\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'india_highest_research', then display it\n",
    "india_2022 = rankings[(rankings[\"Country\"] == \"India\") & (rankings[\"Year\"] == 2022)]\n",
    "sorted_india_research = india_2022.sort_values(by=\"Research Rank\")\n",
    "india_highest_research = sorted_india_research.head(5)[\"Institution\"].tolist()\n",
    "print(india_highest_research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e3f6de02-8c14-48c1-b947-78df245c2e05",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q10...\n",
      "['Indian Institute of Science', 'Tata Institute of Fundamental Research', 'Indian Institute of Technology Bombay', 'Indian Institute of Technology Madras', 'University of Delhi']\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q10\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5af75-b58a-4874-b727-825bbb8221d2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Section 2: Data Across the Years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7260f085-5af7-499e-b576-626c4e11cfec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For the next few questions, we will be analyzing how the rankings of the institutions change across the three years in the dataset. As you might have already noticed, the list of institutions in each year's rankings are different. As a result, for several institutions in the dataset, we do not have the rankings for all three years. Since it will be more challenging to analyze such institutions, we will simply skip them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b732b5db-aec4-46e7-8156-6b191b50d5d9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 11: How **many** institutions have rankings for **all** three years?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800faea8-2cea-4ca6-aeda-7635e37dfed9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be an **integer**. To get started, you have been provided with a code snippet below.\n",
    "\n",
    "**Hint:** You could make **sets** of the institutions that appear in each **DataFrame**, and find their **intersection**. Look up how to find the intersection of two or more sets in Python, on the internet!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf761c99-4d96-44a5-b2fa-1a8431d0b445",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aab85d4c-c715-4c73-b3e1-d27ad91912a8",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q11-code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1897"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'num_institutions_2021_2022_2023', then display it\n",
    "# replace the ... with your code\n",
    "\n",
    "year_2021_ranking_df = rankings[rankings[\"Year\"] == 2021]\n",
    "year_2022_ranking_df = rankings[rankings[\"Year\"] == 2022]\n",
    "year_2023_ranking_df = rankings[rankings[\"Year\"] == 2023]\n",
    "\n",
    "# TODO: make sets of the institutions in each of the three years\n",
    "institutions_2021 = set(year_2021_ranking_df[\"Institution\"])\n",
    "institutions_2022 = set(year_2022_ranking_df[\"Institution\"])\n",
    "institutions_2023 = set(year_2023_ranking_df[\"Institution\"])\n",
    "# TODO: find the intersection of the three sets\n",
    "institutions_2021_2022_2023 = institutions_2021 & institutions_2022 & institutions_2023\n",
    "# TODO: find the length of the intersection\n",
    "num_institutions_2021_2022_2023 = len(institutions_2021_2022_2023)\n",
    "\n",
    "num_institutions_2021_2022_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "11bc0831-0ac9-4fe4-914c-989bb90cab0c",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q11...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q11\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c9a8d-c3bc-4bd9-bc0e-d1ba9f11a241",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Data Structure 1: `institutions_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f63bb9-8417-46f1-9d64-e46bcfba32dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You are now going to create a new **DataFrame** with a **unique** list of institutions which have featured in the rankings for **all** three years, along with their `World Rank` across the three years. Specifically, the **DataFrame** **must** have the following four columns - `'Institution'`, `'2021 ranking'`, `'2022 ranking'`, and `'2023 ranking'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcabb21-29bf-4de5-8236-a70f6dd102b1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ea10d2c2-a424-4040-a764-6bc9b2db5526",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "institutions_df-code"
    ]
   },
   "outputs": [],
   "source": [
    "# define the variable 'institutions_df', but do NOT display it here\n",
    "institutions_list = []\n",
    "for institution in institutions_2021_2022_2023:\n",
    "    institution_data = {\n",
    "        \"Institution\": institution,\n",
    "        \"2021 ranking\": year_2021_ranking_df[year_2021_ranking_df[\"Institution\"] == institution][\"World Rank\"].iloc[0],\n",
    "        \"2022 ranking\": year_2022_ranking_df[year_2022_ranking_df[\"Institution\"] == institution][\"World Rank\"].iloc[0],\n",
    "        \"2023 ranking\": year_2023_ranking_df[year_2023_ranking_df[\"Institution\"] == institution][\"World Rank\"].iloc[0],\n",
    "    }\n",
    "    institutions_list.append(institution_data)\n",
    "institutions_df = pd.DataFrame(institutions_list)\n",
    "# TODO: initalize an empty list to store the list of institutions\n",
    "# TODO: loop through the variable 'institutions_2021_2022_2023' defined above\n",
    "    # TODO: create a new dictionary with the necessary key/value pairs\n",
    "    # TODO: append the dictionary to the list\n",
    "# TODO: create the DataFrame from the list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0775b6f8-883d-4555-9ac6-cbb3cff65bdd",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for institutions_df...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"institutions_df\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d28180-76ae-4555-b49d-6797e91d90e7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 12: Between the years *2022* and *2023*, **list** the institutions which have seen an **improvement** in their `World Rank` by **more than** *200* ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6539a-bc87-422f-b5be-d175c8c7a91d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **list** of institution names. The **order** does **not** matter. You **must** use the DataFrame `institutions_df` to answer this question.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "1. In pandas, subtraction of two columns can be simply done using subtraction(`-`) operator. For example,\n",
    "``` python\n",
    "df[\"difference\"] = df[\"column1\"] - df[\"column2\"]\n",
    "```\n",
    "will create a *new column* `difference` with the difference of the values from the columns `column1` and `column2`.\n",
    "2. Note that an *improved* ranking means that the `World Rank` has *decreased*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404153b-ff37-47f0-8dcb-88568c5ff868",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# compute and store the answer in the variable 'improved_institutions', then display it\n",
    "institutions_df[\"difference\"] = institutions_df[\"2022 ranking\"] - institutions_df[\"2023 ranking\"]\n",
    "improved_institutions = institutions_df[institutions_df[\"difference\"] > 200][\"Institution\"].tolist()\n",
    "improved_institutionsPoints possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "584c96bd-c7b5-4027-9cd5-b76978535090",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q12-code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['University of Reims Champagne-Ardenne',\n",
       " 'University of Picardie Jules Verne',\n",
       " 'Okinawa Institute of Science and Technology',\n",
       " 'Addis Ababa University',\n",
       " 'University of Western Brittany',\n",
       " 'University of Caen Normandy',\n",
       " 'University of Technology of Belfort-Montbéliard']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'improved_institutions', then display it\n",
    "institutions_df[\"difference\"] = institutions_df[\"2022 ranking\"] - institutions_df[\"2023 ranking\"]\n",
    "improved_institutions = institutions_df[institutions_df[\"difference\"] > 200][\"Institution\"].tolist()\n",
    "improved_institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "956e5756-2b84-4ce6-abfb-49f2a9bbe84a",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q12...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q12\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21286d90-4be6-46f5-8ec2-27fc4b2d012e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 13: Between the years *2021* and *2023*, which institution had the **third largest** change in its `World Rank`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c37f6-fcb3-4e51-b31e-f868fe6561e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **string** representing the name of the institution with the **third greatest absolute difference** between its `World Rank` in 2021 and 2023. You **must** use the DataFrame `institutions_df` to answer this question. Feel free add a new column to the DataFrame, so long as you do not modify the existing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00dc2c-ad71-45f4-8a30-f8b085084a86",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a285e1c0-35f4-4103-a7e8-181617da5f0c",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q13-code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Huzhou University'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'third_most_change_inst', then display it\n",
    "institutions_df[\"absolute_change\"] = abs(institutions_df[\"2021 ranking\"] - institutions_df[\"2023 ranking\"])\n",
    "sorted_institutions = institutions_df.sort_values(by=\"absolute_change\", ascending = False)\n",
    "third_most_change_inst = sorted_institutions.iloc[2][\"Institution\"]\n",
    "third_most_change_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00ae09d4-830f-43d1-aaca-08b22565988a",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q13...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q13\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47427b46-cf8c-4239-a8bc-7a4eaf6740c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 14: For all the three years, find the **number** of institutions that **improved** their `World Rank` between **each year** by **at least** 5 ranks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc60fbe-ec66-4421-a67d-4526843bb431",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be an **integer** representing the number of institutions whose `World Rank` **decreased** each year by **at least** 5 ranks. You **must** use the DataFrame `institutions_df` to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de9090-3db3-4bf1-a655-5ee13220967b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc588a32-e3df-4fc1-a37a-5b0d7e6b5b39",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q14-code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'five_improved', then display it\n",
    "institutions_df[\"improvement_2021_2022\"] = institutions_df[\"2021 ranking\"] - institutions_df[\"2022 ranking\"]\n",
    "institutions_df[\"improvement_2022_2023\"] = institutions_df[\"2022 ranking\"] - institutions_df[\"2023 ranking\"]\n",
    "improved_institutions = institutions_df[\n",
    "    (institutions_df[\"improvement_2021_2022\"] >= 5) & \n",
    "    (institutions_df[\"improvement_2022_2023\"] >= 5)\n",
    "]\n",
    "\n",
    "five_improved = len(improved_institutions)\n",
    "five_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49a7615c-b67b-4b99-9ae9-8b571c7aa06a",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q14...\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q14\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df16797-1edc-4077-99b6-13c0e4fb77ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 15: In the `Year` *2021*, **list** the institutions which do **not** feature in the **top** *50* in the world based on `World Rank`, but have a `Employability Rank` **less than or equal** to *25*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba59830-d7b4-4896-af20-42b26ac2e574",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **list** of institutions. The **order** does **not** matter. You **must** use the `year_2021_ranking_df` DataFrame that you created in Question 11 to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2131f64-2d18-4e5a-80d6-458bc74c7932",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "72039c6e-9afd-4d92-baeb-74f5b4d996b8",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q15-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Keio University', 'INSEAD', \"École nationale d'administration\", 'HEC Paris', 'China Europe International Business School', 'International Institute for Management Development', 'École des ponts ParisTech', 'Indian Institute of Management Ahmedabad', 'Stockholm School of Economics', 'Hitotsubashi University', 'Central Party School of the Communist Party of China', 'Graduate Faculty, General Research Institute For Nonferrous Metals']\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'only_top_employability', then display it\n",
    "only_top_employability = year_2021_ranking_df[\n",
    "    (year_2021_ranking_df[\"World Rank\"] > 50) & \n",
    "    (year_2021_ranking_df[\"Employability Rank\"] <= 25)\n",
    "][\"Institution\"].tolist()\n",
    "print(only_top_employability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "231cc489-f629-4e2e-b8ae-d3128a8446af",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q15...\n",
      "['Keio University', 'INSEAD', \"École nationale d'administration\", 'HEC Paris', 'China Europe International Business School', 'International Institute for Management Development', 'École des ponts ParisTech', 'Indian Institute of Management Ahmedabad', 'Stockholm School of Economics', 'Hitotsubashi University', 'Central Party School of the Communist Party of China', 'Graduate Faculty, General Research Institute For Nonferrous Metals']\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q15\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e80e02-366a-4df2-a9ce-5e6fb3addf24",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 16: **List** the universities which ranked in the **top** 50 of world rankings (`World Rank`) in the `Year` *2021* but **failed** to do so in the `Year` *2023*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a718cec-e486-45d7-9ccd-95bfec7c02c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **list** of institutions. The **order** does **not** matter. You **must** use the `year_2021_ranking_df` and `year_2023_ranking_df` DataFrames that you created in Question 11 to answer this question.\n",
    "\n",
    "**Hints:**\n",
    "1. There could be institutions that are ranked in the **top** 50 in *2021* but do not feature in *2023* at all; you still want to include them in your list.\n",
    "2. You can use `sort_values` and `iloc` to identify the **top** 50 institutions.\n",
    "3. Given two *sets* `A` and `B`, you can find the elements which are in `A` but not in `B` using `A - B`. For example,\n",
    "```python\n",
    "set_A = {10, 20, 30, 40, 50}\n",
    "set_B = {20, 40, 70}\n",
    "set_A - set_B == {10, 30, 50} # elements which are in set_A but not in set_B\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e811a-49a7-4e84-ad08-72280bf0df9f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7c7a0a57-9f19-4742-b041-bb8850e18d9f",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q16-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rockefeller University', 'University of Washington - Seattle', 'Rutgers University–New Brunswick', 'University of British Columbia', 'University of Paris']\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'top_50_only_2021', then display it\n",
    "top_50_2021 = set(year_2021_ranking_df[year_2021_ranking_df[\"World Rank\"] <= 50][\"Institution\"])\n",
    "top_50_2023 = set(year_2023_ranking_df[year_2023_ranking_df[\"World Rank\"] <= 50][\"Institution\"])\n",
    "top_50_only_2021 = list(top_50_2021 - top_50_2023)\n",
    "print(top_50_only_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "42aa9ffc-a569-4bda-a2da-62aa1010140b",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q16...\n",
      "['Rockefeller University', 'University of Washington - Seattle', 'Rutgers University–New Brunswick', 'University of British Columbia', 'University of Paris']\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q16\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5efc5c-52f1-48ce-a22a-bc340b8794c4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 17: **List** the countries which have **at least** *5* and **at most** *10* institutions featuring in the **top** *100* of world rankings (`World Rank`) in the `Year` *2023*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59dc08f-05c3-4068-9b66-9560ea6cc987",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **list**.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "1. In a **DataFrame**, to find the **number** of times each unique value in a column repeats, you can use the `DataFrame.value_counts` method. For example,\n",
    "``` python\n",
    "rankings[\"Country\"].value_counts()\n",
    "```\n",
    "would output a `pandas` **Series** with the **indices** being the unique values of `Country` and the **values** being the **number** of times each country has featured in the `rankings` **DataFrame**. You can find the documentation [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.value_counts.html) or by using the `help` function in a separate cell. You can adapt this code to find the number of institutions from each country that features in the `Year` *2023*.\n",
    "2. Just like with **DataFrames**, you can use Boolean indexing on **Series**. For example, try something like this in a separate cell below:\n",
    "```python\n",
    "a = pd.Series([100, 200, 300])\n",
    "a[a > 100]\n",
    "```\n",
    "3. You can extract the **indices** of a **Series**, `s` with `s.index`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670c14eb-ee23-41a4-a8a4-5aaf45828696",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6b0f0e0b-5987-4b46-b858-332921e7d59c",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q17-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United Kingdom', 'China', 'Germany', 'France']\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'almost_top_countries', then display it\n",
    "top_100_2023 = year_2023_ranking_df[year_2023_ranking_df[\"World Rank\"] <= 100]\n",
    "country_counts = top_100_2023[\"Country\"].value_counts()\n",
    "almost_top_countries = country_counts[(country_counts >= 5) & (country_counts <= 10)].index.tolist()\n",
    "print(almost_top_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6a1ada20-1e78-4db1-a4c8-1cfcc96e8700",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q17...\n",
      "['United Kingdom', 'China', 'Germany', 'France']\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q17\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83f37ca-e7a0-421c-8b4e-98f0383c555c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Section 3: BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6036bfa4-706a-45f1-9757-7b2ce9da66c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In real life, you don't often have data in nice JSON format like `rankings.json`. Instead, data needs to be *scraped* from multiple webpages and requires some cleanup before it can be used.\n",
    "\n",
    "Most of the projects in CS220 have used data obtained via web scraping, including this one. For p12, as explained above, we obtained the data by scraping the following websites:\n",
    "\n",
    "* https://cwur.org/2020-21.php\n",
    "* https://cwur.org/2021-22.php\n",
    "* https://cwur.org/2023.php\n",
    "\n",
    "Our `rankings.json` file was created using data from these webpages. For the rest of this project, you will write the code to **recreate** `rankings.json` file from the tables in these html pages yourself! We also do **not** want all students in this class to be making multiple requests to the webpages above, as that could be very costly for the people managing the webpages. Instead, we have made **copies** of the webpages above, which can be found here:\n",
    "\n",
    "* https://cs220.cs.wisc.edu/projects/data/2021.html\n",
    "* https://cs220.cs.wisc.edu/projects/data/2022.html\n",
    "* https://cs220.cs.wisc.edu/projects/data/2023.html\n",
    "\n",
    "Before you can parse these html files, you must first *download* them. You **must** use your `download` function to download these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac9df50-899d-490a-9e31-5e3979cc7410",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Download `2021.html`, `2022.html` and `2023.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050e5934-fee1-48a1-869c-33b0e86ffb18",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the lab portion, you downloaded the files `2021.html`, `2022.html` and `2023.html`. Just in case they are no longer in your directory, use the `download` function you previously created to download the contents of each of the URLs above and save them into files. Name the files `2021.html`, `2022.html` and `2023.html` based on the respective URL if you need to redownload them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b891bb-ae09-4962-8018-f4d7db4c4fcf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b99f83c-db5a-4beb-a238-b83f7d621ab9",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "downloads-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021.html already exists!\n",
      "2022.html already exists!\n",
      "2023.html already exists!\n"
     ]
    }
   ],
   "source": [
    "# use the 'download' function to download the data from the webpage and save the return value in 'message_2021'\n",
    "# 'https://cs220.cs.wisc.edu/projects/data/2021.html'\n",
    "# to the file '2021.html'\n",
    "message_2021 = download(\"https://cs220.cs.wisc.edu/projects/data/2021.html\", \"2021.html\")\n",
    "\n",
    "# use the 'download' function to download the data from the webpage and save the return value in 'message_2022'\n",
    "# 'https://cs220.cs.wisc.edu/projects/data/2022.html'\n",
    "# to the file '2022.html'\n",
    "message_2022 = download(\"https://cs220.cs.wisc.edu/projects/data/2022.html\", \"2022.html\")\n",
    "\n",
    "# use the 'download' function to download the data from the webpage and save the return value in 'message_2023'\n",
    "# 'https://cs220.cs.wisc.edu/projects/data/2023.html'\n",
    "# to the file '2023.html'\n",
    "message_2023 = download(\"https://cs220.cs.wisc.edu/projects/data/2023.html\", \"2023.html\")\n",
    "\n",
    "print(message_2021)\n",
    "print(message_2022)\n",
    "print(message_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "91411e7b-cb73-47ee-be6b-9519ee84e10f",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for downloads...\n",
      "2021.html already exists!\n",
      "2022.html already exists!\n",
      "2023.html already exists!\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"downloads\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72681b8-b471-4dc2-a12c-58fd4e530588",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 18: Use `BeautifulSoup` to **parse** `2021.html`, and find the **table** containing the ranking data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffaa55b-df36-4036-9097-7aff42a82aa0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Extract the **column names** of this table and the first row of the table to create a **dictionary** where the column headers are the keys and the corresponding values are extracted from the **first** row.\n",
    "\n",
    "You do **not** have to perform any typecasting of the data **yet**. Your output **must** be a **dictionary** having the format as given below:\n",
    "```python\n",
    "{\n",
    "    'World Rank': '1',\n",
    "    'Institution': 'Harvard University',\n",
    "    'Country': 'USA',\n",
    "    'National Rank': '1',\n",
    "    'Education Rank': '1',\n",
    "    'Employability Rank': '1',\n",
    "    'Faculty Rank': '1',\n",
    "    'Research Rank': '1',\n",
    "    'Score': '100'\n",
    "}\n",
    "```\n",
    "\n",
    "**Hints:** You can use the `find` or `find_all` **methods** to identify the table and its header. Or you can use the `parse_html` function you defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81585623-bb0b-4add-951c-4050dd3ba684",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "700027a6-c974-47b4-9b11-5f0046166f76",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q18-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'World Rank': '1', 'Institution': 'Harvard University', 'Country': 'USA', 'National Rank': '1', 'Education Rank': '1', 'Employability Rank': '1', 'Faculty Rank': '1', 'Research Rank': '1', 'Score': '100'}\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'first_dict', then display it\n",
    "with open(\"2021.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    file_content = file.read()\n",
    "soup = BeautifulSoup(file_content, \"html.parser\")\n",
    "table = soup.find(\"table\")\n",
    "header_tags = table.find_all(\"th\")\n",
    "headers = [tag.get_text().strip() for tag in header_tags]\n",
    "first_row = table.find_all(\"tr\")[1]  \n",
    "cells = first_row.find_all(\"td\")\n",
    "values = [cell.get_text().strip() for cell in cells]\n",
    "first_dict = dict(zip(headers, values))\n",
    "\n",
    "print(first_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c3457421-21aa-4278-aa74-c2c5dcf22fb6",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q18...\n",
      "{'World Rank': '1', 'Institution': 'Harvard University', 'Country': 'USA', 'National Rank': '1', 'Education Rank': '1', 'Employability Rank': '1', 'Faculty Rank': '1', 'Research Rank': '1', 'Score': '100'}\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q18\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaca2ae-1a44-4f71-9aab-28ac372d0e61",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 19: Calculate the **average** score of the **first** 5 institutions in the file `2021.html`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d064a74f-0a91-4328-b97e-613285811897",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Your output **must** be a **float** calculated by averaging the scores from the first 5 dictionaries in the file. You **must** use the `parse_html` function to parse the file, and **slice** the list such that you would only loop through the **first five** institutions. For each **dictionary** in the **list** you must use the `Score` key to get the score for that particular institution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b067c393-8fea-49d4-b072-5193778837e7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b65f9b70-9b35-47d5-8cec-11fbef3d0bd3",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q19-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.84\n"
     ]
    }
   ],
   "source": [
    "# compute and store the answer in the variable 'avg_top_5', then display it\n",
    "data_2021 = parse_html(\"2021.html\")\n",
    "top_5_institutions = data_2021[:5]\n",
    "avg_top_5 = sum(float(inst[\"Score\"]) for inst in top_5_institutions) / len(top_5_institutions)\n",
    "\n",
    "print(avg_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6dc9e637-0164-405c-b36c-186763e9e0d1",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q19...\n",
      "95.84\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q19\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5774db-b115-419f-8cbf-f942b60999d0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 20: Parse the contents of the **three** files `2021.html`, `2022.html`, and `2023.html` and combine them to create a **single** file named `my_rankings.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc8b0e-6766-483f-bd09-0b9f094dde48",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You **must** create a **file** named `my_rankings.json` in your current directory. The contents of this file **must** be **identical** to `rankings.json`.\n",
    "\n",
    "**Hints:**\n",
    "1. Using the logic from the question above, combine the data from these three files into a single list of dicts, and write it into the file `\"my_rankings.json\"`.\n",
    "2. You can use the `write_json` function that was introduced in lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee263fc-1ef6-4abb-bcc3-2331e7ee1c12",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Points possible: 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "019620c8-fec9-40fa-8470-96642336e988",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "q20-code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_rankings.json has been created!\n"
     ]
    }
   ],
   "source": [
    "# the 'write_json' function from lecture has been provided for you here\n",
    "def write_json(path, data):\n",
    "    with open(path, 'w', encoding = \"utf-8\") as f:\n",
    "        json.dump(data, f, indent = 2)\n",
    "data_2021 = parse_html(\"2021.html\")\n",
    "data_2022 = parse_html(\"2022.html\")\n",
    "data_2023 = parse_html(\"2023.html\")\n",
    "my_rankings = data_2021 + data_2022 + data_2023\n",
    "write_json(\"my_rankings.json\", my_rankings)\n",
    "print(\"my_rankings.json has been created!\")\n",
    "# define a variable that contains the combined contents of the individual html files called 'my_rankings'\n",
    "# `my_rankings` should be a list of dictionaries\n",
    "\n",
    "# parse the three files with parse_html and write the contents into 'my_rankings.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e9224d14-ab7a-45f3-be45-013fa0afeea5",
   "metadata": {
    "deletable": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you saved the notebook before running this cell. Running check for q20...\n",
      "my_rankings.json has been created!\n",
      "Great job! You passed all test cases for this question.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_grader.check(\"q20\", should_get_llm_feedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf7b4a-dcd5-4e7d-8681-3dd830a50505",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da8a55-5599-47be-b7cc-a4ee2df293b0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Make sure you have run all cells in your notebook in order before submitting on Gradescope. Your notebook should not contain any uncaught Exceptions, otherwise the Gradescope autograder will not give you any points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "semester": "f24"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
